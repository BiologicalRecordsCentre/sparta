[{"path":"/articles/vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Sparta provides range tools analysing trends species occurrence data based work presented Isaac et al (2014). data used method ‘’. ‘’ typically species name. ‘’ location observation, sometimes referred site. typically 1km, 2km 10km grid square also none regular location field sites counties. ‘’ time observation made, requirements differ methods. methods require date others require aggregate dates time periods comparison. methods described require multi species data. use information across species assess biases. vignette run methods show can used reproducible examples.","code":""},{"path":"/articles/vignette.html","id":"installation","dir":"Articles","previous_headings":"Introduction","what":"Installation","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Installing package easy can done CRAN. Alternatively development version can installed GitHub. NOTE: JAGS must installed R package installation work. JAGS can found - http://sourceforge.net/projects/mcmc-jags/files/JAGS/ functions sparta cover range tasks. Primarily focused analysing trends species occurrence data accounting biases (see Isaac et al, 2014). vignette step functions others can understand package works. questions can find package maintainers email address using maintainer('sparta'), issues bugs can report ","code":"# Install the package from CRAN # THIS WILL WORK ONLY AFTER THE PACKAGE IS PUBLISHED # install.packages('sparta')  # Or install the development version from GitHub library(devtools) # install_github('biologicalrecordscentre/sparta') # Once installed, load the package library(sparta) ## Loading required package: lme4 ## Loading required package: Matrix"},{"path":[]},{"path":"/articles/vignette.html","id":"create-some-example-data","dir":"Articles","previous_headings":"Modelling methods","what":"Create some example data","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Clearly using sparta want use data, however perhaps planning stage project? code shows create example data can try sparta’s functionality. general format data need functions sparta. taxa site columns characters time_period column ideally date can cases numeric. many sources wildlife observation data including GBIF (Global Biodiversity Information Facility) NBN gateway (National Biodiversity Network). repositories R packages allow download type data straight R session (see rgbif rnbn details)","code":"# Create data n <- 8000 # size of dataset nyr <- 50 # number of years in data nSamples <- 200 # set number of dates nSites <- 100 # set number of sites set.seed(125) # set a random seed  # Create somes dates first <- as.Date(strptime(\"1950/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(1950+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set semi-randomly taxa_probabilities <- seq(from = 0.1, to = 0.7, length.out = 26) taxa <- sample(letters, size = n, TRUE, prob = taxa_probabilities)  # sites are visited semi-randomly site_probabilities <- seq(from = 0.1, to = 0.7, length.out = nSites) site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE, prob = site_probabilities)  # the date of visit is selected semi-randomly from those created earlier time_probabilities <- seq(from = 0.1, to = 0.7, length.out = nSamples) time_period <- sample(rDates, size = n, TRUE, prob = time_probabilities)  myData <- data.frame(taxa, site, time_period)  # Let's have a look at the my example data head(myData) ##   taxa site time_period ## 1    r  A51  1970-01-14 ## 2    v  A87  1980-09-29 ## 3    e  A56  1996-04-14 ## 4    z  A28  1959-01-16 ## 5    r  A77  1970-09-21 ## 6    x  A48  1990-02-25"},{"path":"/articles/vignette.html","id":"assessing-the-quality-of-data","dir":"Articles","previous_headings":"Modelling methods","what":"Assessing the quality of data","title":"sparta - Species Presence/Absence R Trends Analyses","text":"can useful look data analyses. example important understand biases data. function dataDiagnostics designed help .  plot produced shows number records year top plot average list length box plot bottom. List length number taxa observed visit site, visit taken unique combination ‘’ ‘’. trend number observations across time uncommon formal test trend performed form linear model. Trends number records time handled methods presented sparta variety different ways. Trends list length tested manner, returned console. list length can cause methods reporting rate methods fail (see ‘LessEffortPerVisit’ scenario Isaac et al (2014)) Unsurprisingly, since random dataset, trend either number records list length time. function also works numeric time period year  want view results detail can interrogate object results","code":"# Run some data diagnostics on our data results <- dataDiagnostics(taxa = myData$taxa,                            site = myData$site,                            time_period = myData$time_period,                            progress_bar = FALSE) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): 94 ## out of 8000 observations will be removed as duplicates ## ## Linear model outputs ## ##  ## There is no detectable change in the number of records over time: ##  ##                 Estimate   Std. Error    t value  Pr(>|t|) ## (Intercept) -894.8997359 1710.0719088 -0.5233112 0.6031654 ## time_period    0.5342617    0.8660553  0.6168910 0.5402219 ##  ##  ## There is no detectable change in list lengths over time: ##  ##                 Estimate   Std. Error    z value     Pr(>|z|) ## (Intercept) 2.390402e-01 1.208657e-02 19.7773477 4.665954e-87 ## time_period 1.098369e-06 2.135956e-06  0.5142282 6.070924e-01 # Run some data diagnostics on our data, now time_period # is set to be a year results <- dataDiagnostics(taxa = myData$taxa,                            site = myData$site,                            time_period = as.numeric(format(myData$time_period, '%Y')),                            progress_bar = FALSE) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): ## 419 out of 8000 observations will be removed as duplicates ## ## Linear model outputs ## ##  ## There is no detectable change in the number of records over time: ##  ##                 Estimate   Std. Error    t value  Pr(>|t|) ## (Intercept) -894.8997359 1710.0719088 -0.5233112 0.6031654 ## time_period    0.5342617    0.8660553  0.6168910 0.5402219 ##  ##  ## There is no detectable change in list lengths over time: ##  ##                  Estimate   Std. Error    z value  Pr(>|z|) ## (Intercept) -0.6465523185 1.5554513917 -0.4156686 0.6776525 ## time_period  0.0007201245 0.0007874907  0.9144546 0.3604780 # See what is in results.. names(results) ## [1] \"RecordsPerYear\"  \"VisitListLength\" \"modelRecs\"       \"modelList\" # Let's have a look at the details head(results$RecordsPerYear) ## RecordsPerYear ## 1950 1951 1952 1953 1954 1955  ##  224   69  147  181  119  218 head(results$VisitListLength) ##   time_period site listLength ## 1        1950 A100          3 ## 2        1950  A11          1 ## 3        1950  A12          2 ## 4        1950  A13          1 ## 5        1950  A15          1 ## 6        1950  A16          2 summary(results$modelRecs) ##  ## Call: ## glm(formula = count ~ time_period, data = mData) ##  ## Coefficients: ##              Estimate Std. Error t value Pr(>|t|) ## (Intercept) -894.8997  1710.0719  -0.523    0.603 ## time_period    0.5343     0.8661   0.617    0.540 ##  ## (Dispersion parameter for gaussian family taken to be 7809.915) ##  ##     Null deviance: 377848  on 49  degrees of freedom ## Residual deviance: 374876  on 48  degrees of freedom ## AIC: 594.01 ##  ## Number of Fisher Scoring iterations: 2 summary(results$modelList) ##  ## Call: ## glm(formula = listLength ~ time_period, family = \"poisson\", data = space_time) ##  ## Coefficients: ##               Estimate Std. Error z value Pr(>|z|) ## (Intercept) -0.6465523  1.5554514  -0.416    0.678 ## time_period  0.0007201  0.0007875   0.914    0.360 ##  ## (Dispersion parameter for poisson family taken to be 1) ##  ##     Null deviance: 2737.1  on 3489  degrees of freedom ## Residual deviance: 2736.3  on 3488  degrees of freedom ## AIC: 11607 ##  ## Number of Fisher Scoring iterations: 5"},{"path":"/articles/vignette.html","id":"telfer","dir":"Articles","previous_headings":"Modelling methods","what":"Telfer","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Telfer’s change index designed assess relative change range size species two time periods (Telfer et al, 2002). simple method robust low power detect trends exist. method designed compare two time period sparta can take many time periods complete pairwise comparisons. data quite correct format Telfer since used compare time periods time_period column date. can fix using date2timeperiod function. can see new column indicates time period date falls 1 earliest time period, 2 second . function also work instead single date record date range can see example date range spans boundaries time periods NA returned. Now data right format can use telfer function analyse data. Telfer index species standardized residual linear regression across species measure relative change average real trend across species obscured (Isaac et al (2014); Telfer et al, 2002).Telfer used comparing two time periods telfer function pair-wise comparisons. get warning message indicating large number rows removed duplicates. occurs since now aggregating records time periods therefore creating large number duplicates. results give change index species (rows) pairwise comparisons time periods (columns).","code":"## Create a new column for the time period # First define my time periods time_periods <- data.frame(start = c(1950, 1960, 1970, 1980, 1990),                            end = c(1959, 1969, 1979, 1989, 1999))  time_periods ##   start  end ## 1  1950 1959 ## 2  1960 1969 ## 3  1970 1979 ## 4  1980 1989 ## 5  1990 1999 # Now use these to assign my dates to time periods myData$tp <- date2timeperiod(myData$time_period, time_periods)  head(myData) ##   taxa site time_period tp ## 1    r  A51  1970-01-14  3 ## 2    v  A87  1980-09-29  4 ## 3    e  A56  1996-04-14  5 ## 4    z  A28  1959-01-16  1 ## 5    r  A77  1970-09-21  3 ## 6    x  A48  1990-02-25  5 ## Create a dataset where we have date ranges Date_range <- data.frame(startdate = myData$time_period,                          enddate = (myData$time_period + 600))  head(Date_range) ##    startdate    enddate ## 1 1970-01-14 1971-09-06 ## 2 1980-09-29 1982-05-22 ## 3 1996-04-14 1997-12-05 ## 4 1959-01-16 1960-09-07 ## 5 1970-09-21 1972-05-13 ## 6 1990-02-25 1991-10-18 # Now assign my date ranges to time periods Date_range$time_period <- date2timeperiod(Date_range, time_periods)  head(Date_range) ##    startdate    enddate time_period ## 1 1970-01-14 1971-09-06           3 ## 2 1980-09-29 1982-05-22           4 ## 3 1996-04-14 1997-12-05           5 ## 4 1959-01-16 1960-09-07          NA ## 5 1970-09-21 1972-05-13           3 ## 6 1990-02-25 1991-10-18           5 # Here is our data head(myData) ##   taxa site time_period tp ## 1    r  A51  1970-01-14  3 ## 2    v  A87  1980-09-29  4 ## 3    e  A56  1996-04-14  5 ## 4    z  A28  1959-01-16  1 ## 5    r  A77  1970-09-21  3 ## 6    x  A48  1990-02-25  5 telfer_results <- telfer(taxa = myData$taxa,                          site = myData$site,                          time_period = myData$tp,                          minSite = 2) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period, : ## 2541 out of 8000 observations will be removed as duplicates ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y' are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y' are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y' are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y', 'Nsite_2.x', 'Nsite_2.y' are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y', 'Nsite_2.x', 'Nsite_2.y' are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y', 'Nsite_2.x', 'Nsite_2.y', 'Nsite_3.x', 'Nsite_3.y' ## are duplicated in the result ## Warning in merge.data.frame(a, b, all = TRUE, by = \"taxa\"): column names ## 'Nsite_1.x', 'Nsite_1.y', 'Nsite_2.x', 'Nsite_2.y', 'Nsite_3.x', 'Nsite_4.x', ## 'Nsite_3.y', 'Nsite_5.x', 'Nsite_4.y', 'Nsite_5.y' are duplicated in the result head(telfer_results) ##   taxa Nsite_1.x Nsite_2.x  Telfer_1_2 Nsite_1.y Nsite_3.x   Telfer_1_3 ## 1    a        13        16 -0.67842545        13        13 -1.744577671 ## 2    b        18        19 -0.90368128        18        21 -0.841219630 ## 3    c        16        22  0.96096754        16        22 -0.008737329 ## 4    d        17        23  0.79744179        17        21 -0.558165922 ## 5    e        23        27 -0.01856808        23        32  0.490523483 ## 6    f        28        28 -0.80201507        28        33 -0.412461197 ##   Nsite_1.x Nsite_4.x Telfer_1_4 Nsite_1.y Nsite_5.x Telfer_1_5 Nsite_2.y ## 1        13         8 -1.8073843        13        17 -0.7000801        17 ## 2        18        16 -0.8697828        18        18 -1.5449132        20 ## 3        16        19  0.2181534        16        23  0.3726534        22 ## 4        17        21  0.3848417        17        30  1.6642357        23 ## 5        23        20 -1.0901348        23        21 -1.6500473        27 ## 6        28        25 -1.0846426        28        38  0.3817399        29 ##   Nsite_3.y Telfer_2_3 Nsite_2.x Nsite_4.y Telfer_2_4 Nsite_2.y Nsite_5.y ## 1        13 -1.8352888        17         8 -2.1097232        17        17 ## 2        21 -0.5139840        20        16 -0.6234749        20        18 ## 3        22 -0.7254485        22        19 -0.3891040        22        23 ## 4        21 -1.1759409        23        21 -0.1875890        23        30 ## 5        32  0.3450083        27        20 -1.1254544        27        21 ## 6        33  0.1657078        29        25 -0.5122655        29        38 ##   Telfer_2_5 Nsite_3.x Nsite_4.x Telfer_3_4 Nsite_3.y Nsite_5.x Telfer_3_5 ## 1 -0.4557972        13         8 -1.1728237        13        17  0.8437536 ## 2 -0.8326960        21        16 -0.3171487        21        18 -1.1756988 ## 3 -0.3595835        22        19  0.3549603        22        23 -0.2184517 ## 4  0.5294236        21        21  1.2663488        21        30  1.3562488 ## 5 -1.7153826        32        20 -1.8881411        32        21 -2.1972910 ## 6  0.8827473        33        25 -0.8383498        33        38  0.4662370 ##   Nsite_4.y Nsite_5.y Telfer_4_5 ## 1         8        17  1.4880569 ## 2        16        18 -0.8995878 ## 3        19        23 -0.3834038 ## 4        21        30  0.6466352 ## 5        20        21 -1.0810351 ## 6        25        38  1.3111555"},{"path":"/articles/vignette.html","id":"reporting-rate-models","dir":"Articles","previous_headings":"Modelling methods","what":"Reporting Rate Models","title":"sparta - Species Presence/Absence R Trends Analyses","text":"reporting rates models sparta either GLMs GLMMs year continuous covariate flexible, giving user number options analyses. options include addition covariates account biases data including random site effect fixed effect list length. Isaac et al (2014) shown reporting rate models can susceptible type 1 errors certain scenarios site list length covariates models performed better data biased. methods found perform simple methods like Telfer. common feature among models quantity consideration ‘probability recorded’. binomial models used (default), ’s ‘probability average visit’ Bernoulli version probability recorded per time period.","code":""},{"path":"/articles/vignette.html","id":"data-selection","dir":"Articles","previous_headings":"Modelling methods > Reporting Rate Models","what":"Data selection","title":"sparta - Species Presence/Absence R Trends Analyses","text":"undertaking modelling data can subset effort remove data may introduce bias. Model sub-setting found reduce power Isaac et al (2014) can partially deal uneven sampling site. process can also used methods solely applicable reporting rate models. first function allows subset data list length. works , combination ‘’ ‘’ (visit), number species observed (list length). records come list meets list length criteria dropped. also able subset number times site sampled. function siteSelectionMinTP . time_period date, case, minTP minimum number years site must sampled included subset. can see example minTP specifies number years site must sampled order included. However, dataset well sampled might interested another measure time. example, might want sites observed least 60 months. Let’s see done. Following method Roy et al (2012) can combine two functions subset length lists number years sites sampled. wrapped function siteSelection takes arguments previous two functions plus argument LFirst indicates whether data subset list length first (TRUE) second (FALSE).","code":"# Select only records which occur on lists of length 2 or more myDataL <- siteSelectionMinL(taxa = myData$taxa,                              site = myData$site,                              time_period = myData$time_period,                              minL = 2) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): 94 ## out of 8000 observations will be removed as duplicates head(myDataL) ##   taxa site time_period ## 1    u   A1  1952-11-16 ## 2    n   A1  1952-11-16 ## 3    x   A1  1960-06-06 ## 4    s   A1  1960-06-06 ## 5    x   A1  1999-08-03 ## 6    d   A1  1999-08-03 # We now have a much smaller dataset after subsetting nrow(myData) ## [1] 8000 nrow(myDataL) ## [1] 3082 # Select only data from sites sampled in at least 10 years myDataTP <- siteSelectionMinTP(taxa = myData$taxa,                                site = myData$site,                                time_period = myData$time_period,                                minTP = 10) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): 94 ## out of 8000 observations will be removed as duplicates head(myDataTP) ##   taxa site time_period ## 1    r  A51  1970-01-14 ## 2    v  A87  1980-09-29 ## 3    e  A56  1996-04-14 ## 4    z  A28  1959-01-16 ## 5    r  A77  1970-09-21 ## 6    x  A48  1990-02-25 # Here we have only lost a small number rows, this is because # many sites in our data are visited in a lot of years. Those # rows that have been removed are duplicates nrow(myData) ## [1] 8000 nrow(myDataTP) ## [1] 7906 # We need to create a new column to represent unique months # this could also be any unit of time you wanted (week, decade, etc.)  # This line returns a unique character for each month unique_Months <- format(myData$time_period, \"%B_%Y\") head(unique_Months) ## [1] \"January_1970\"   \"September_1980\" \"April_1996\"     \"January_1959\"   ## [5] \"September_1970\" \"February_1990\" # Week could be done like this, see ?strptime for more details unique_Weeks <- format(myData$time_period, \"%U_%Y\") head(unique_Weeks) ## [1] \"02_1970\" \"39_1980\" \"15_1996\" \"02_1959\" \"38_1970\" \"08_1990\" # Now lets subset to records found on 60 months or more myData60Months <- siteSelectionMinTP(taxa = myData$taxa,                                      site = myData$site,                                      time_period = unique_Months,                                      minTP = 60) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): ## 129 out of 8000 observations will be removed as duplicates head(myData60Months) ##   taxa site    time_period ## 1    r  A51   January_1970 ## 2    v  A87 September_1980 ## 3    e  A56     April_1996 ## 5    r  A77 September_1970 ## 6    x  A48  February_1990 ## 7    t  A59   January_1981 # We could merge this back with our original data if # we need to retain the full dates myData60Months <- merge(myData60Months, myData$time_period,                          all.x = TRUE, all.y = FALSE,                         by = \"row.names\") head(myData60Months) ##   Row.names taxa site  time_period          y ## 1         1    r  A51 January_1970 1970-01-14 ## 2        10    w  A81    June_1982 1982-06-19 ## 3       100    v  A91 January_1996 1996-01-29 ## 4      1000    h  A94     May_1990 1981-01-17 ## 5      1001    m  A73   March_1999 1990-05-18 ## 6      1002    b  A59    July_1997 1999-03-05 nrow(myData) ## [1] 8000 nrow(myData60Months) ## [1] 5289 # Subset our data as above but in one go myDataSubset  <- siteSelection(taxa = myData$taxa,                                site = myData$site,                                time_period = myData$time_period,                                minL = 2,                                minTP = 10,                                LFirst = TRUE) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): 94 ## out of 8000 observations will be removed as duplicates head(myDataSubset) ##    taxa site time_period ## 11    y A100  1950-01-04 ## 12    k A100  1950-01-04 ## 13    l A100  1954-01-30 ## 14    o A100  1954-01-30 ## 15    s A100  1954-01-30 ## 16    m A100  1956-02-02 nrow(myDataSubset) ## [1] 2587"},{"path":"/articles/vignette.html","id":"running-reporting-rate-models","dir":"Articles","previous_headings":"Modelling methods > Reporting Rate Models","what":"Running Reporting Rate Models","title":"sparta - Species Presence/Absence R Trends Analyses","text":"subset data using functions (perhaps ) reporting rate models can applied using function reportingRateModel. function offers flexibility model wish fit, allowing user specify whether list length site used covariates, whether -dispersion used, whether family binomial Bernoulli. number variants presented Isaac et al (2014). multi-species data required nessecary model species. fact can save significant amount time modelling species interested .  returned object data frame one row per species. column gives information element model output including covariate estimates, standard errors p-values. object also attributes giving year chosen intercept, number visits dataset model formula used. models can take long time run data set large large number species model. make faster possible parallelise process across species can significantly improve run times. example parallelise example using hte R package snowfall. Using functions possible recreate ‘Well-sampled sites’ method presented Roy et al (2012) Thomas et al (2015). made available function WSS simple wrapper around siteSelection reportingratemodel. variant data subset list length number years site sampled run GLMM site random effect.","code":"# Run the reporting rate model using list length as a fixed effect and  # site as a random effect. Here we only model a few species. system.time({ RR_out <- reportingRateModel(taxa = myData$taxa,                              site = myData$site,                              time_period = myData$time_period,                              list_length = TRUE,                              site_effect = TRUE,                              species_to_include = c('e','u','r','o','t','a','s'),                              overdispersion = FALSE,                              family = 'Bernoulli',                              print_progress = TRUE) }) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period, : ## 94 out of 8000 observations will be removed as duplicates ## Modelling e - Species 1 of 7 ## boundary (singular) fit: see help('isSingular') ## Modelling u - Species 2 of 7  ## Modelling r - Species 3 of 7  ## Modelling o - Species 4 of 7  ## Modelling t - Species 5 of 7 ## boundary (singular) fit: see help('isSingular') ## Modelling a - Species 6 of 7  ## Modelling s - Species 7 of 7 ## boundary (singular) fit: see help('isSingular') ##    user  system elapsed  ##   15.75    0.06   15.81 # Let's have a look at the data that is returned str(RR_out) ## 'data.frame':    7 obs. of  14 variables: ##  $ species_name            : chr  \"e\" \"u\" \"r\" \"o\" ... ##  $ intercept.estimate      : num  -3.99 -2.85 -2.86 -3.09 -3 ... ##  $ year.estimate           : num  -0.005885 -0.006992 -0.003336 0.000192 -0.004111 ... ##  $ log.listlength..estimate: num  1.042 1.252 0.791 1.03 1.288 ... ##  $ intercept.stderror      : num  0.1057 0.0644 0.0675 0.0755 0.0663 ... ##  $ year.stderror           : num  0.00582 0.00341 0.00359 0.00383 0.0036 ... ##  $ log.listlength..stderror: num  0.201 0.118 0.134 0.136 0.124 ... ##  $ intercept.zvalue        : num  -37.7 -44.3 -42.4 -40.9 -45.2 ... ##  $ year.zvalue             : num  -1.0105 -2.0508 -0.9296 0.0502 -1.1418 ... ##  $ log.listlength..zvalue  : num  5.17 10.56 5.9 7.55 10.4 ... ##  $ intercept.pvalue        : num  0 0 0 0 0 ... ##  $ year.pvalue             : num  0.3123 0.0403 0.3526 0.96 0.2536 ... ##  $ log.listlength..pvalue  : num  2.32e-07 4.42e-26 3.71e-09 4.22e-14 2.61e-25 ... ##  $ observations            : num  144 450 398 346 398 73 426 ##  - attr(*, \"intercept_year\")= num 1974 ##  - attr(*, \"min_year\")= num -24.5 ##  - attr(*, \"max_year\")= num 24.5 ##  - attr(*, \"nVisits\")= int 6211 ##  - attr(*, \"model_formula\")= chr \"taxa ~ year + log(listLength) + (1|site)\" # We could plot these to see the species trends with(RR_out,      # Plot graph      {plot(x = 1:7, y = year.estimate,            ylim = range(c(year.estimate - year.stderror,                           year.estimate + year.stderror)),            ylab = 'Year effect (+/- Std Dev)',            xlab = 'Species',            xaxt = \"n\")      # Add x-axis with species names      axis(1, at = 1:7, labels = species_name)      # Add the error bars      arrows(1:7, year.estimate - year.stderror,             1:7, year.estimate + year.stderror,             length = 0.05, angle = 90, code = 3)}      ) # Load in snowfall library(snowfall) ## Loading required package: snow # I have 4 cpus on my PC so I set cpus to 4 # when I initialise the cluster sfInit(parallel = TRUE, cpus = 4) ## R Version:  R version 4.4.0 (2024-04-24 ucrt) ## snowfall 1.84-6.3 initialized (using snow 0.4-4): parallel execution on 4 CPUs. # Export my data to the cluster sfExport('myData')  # I create a function that takes a species name and runs my models RR_mod_function <- function(taxa_name){      library(sparta)      RR_out <- reportingRateModel(species_to_include = taxa_name,                                taxa = myData$taxa,                                site = myData$site,                                time_period = myData$time_period,                                list_length = TRUE,                                site_effect = TRUE,                                overdispersion = FALSE,                                family = 'Bernoulli',                                print_progress = FALSE)   }   # I then run this in parallel system.time({ para_out <- sfClusterApplyLB(c('e','u','r','o','t','a','s'), RR_mod_function) }) ##    user  system elapsed  ##    0.00    0.00    4.62 # Name each element of this output by the species RR_out_combined <- do.call(rbind, para_out)  # Stop the cluster sfStop() ##  ## Stopping cluster # You'll see the output is the same as when we did it serially but the # time taken is shorter. Using a cluster computer with many more than  # 4 cores can greatly reduce run time. str(RR_out_combined) ## 'data.frame':    7 obs. of  14 variables: ##  $ species_name            : chr  \"e\" \"u\" \"r\" \"o\" ... ##  $ intercept.estimate      : num  -3.99 -2.85 -2.86 -3.09 -3 ... ##  $ year.estimate           : num  -0.005885 -0.006992 -0.003336 0.000192 -0.004111 ... ##  $ log.listlength..estimate: num  1.042 1.252 0.791 1.03 1.288 ... ##  $ intercept.stderror      : num  0.1057 0.0644 0.0675 0.0755 0.0663 ... ##  $ year.stderror           : num  0.00582 0.00341 0.00359 0.00383 0.0036 ... ##  $ log.listlength..stderror: num  0.201 0.118 0.134 0.136 0.124 ... ##  $ intercept.zvalue        : num  -37.7 -44.3 -42.4 -40.9 -45.2 ... ##  $ year.zvalue             : num  -1.0105 -2.0508 -0.9296 0.0502 -1.1418 ... ##  $ log.listlength..zvalue  : num  5.17 10.56 5.9 7.55 10.4 ... ##  $ intercept.pvalue        : num  0 0 0 0 0 ... ##  $ year.pvalue             : num  0.3123 0.0403 0.3526 0.96 0.2536 ... ##  $ log.listlength..pvalue  : num  2.32e-07 4.41e-26 3.71e-09 4.22e-14 2.61e-25 ... ##  $ observations            : num  144 450 398 346 398 73 426 ##  - attr(*, \"intercept_year\")= num 1974 ##  - attr(*, \"min_year\")= num -24.5 ##  - attr(*, \"max_year\")= num 24.5 ##  - attr(*, \"nVisits\")= int 6211 ##  - attr(*, \"model_formula\")= chr \"taxa ~ year + log(listLength) + (1|site)\" # Run our data through the well-sampled sites function # This time we run all species WSS_out <- WSS(taxa = myData$taxa,                site = myData$site,                time_period = myData$time_period,                minL = 2,                minTP = 10,                print_progress = FALSE) ## Warning in errorChecks(taxa = taxa, site = site, time_period = time_period): 94 ## out of 8000 observations will be removed as duplicates ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') # The data is returned in the same format as from reportingRateModel str(WSS_out) ## 'data.frame':    26 obs. of  10 variables: ##  $ species_name      : chr  \"r\" \"v\" \"e\" \"z\" ... ##  $ intercept.estimate: num  -2.29 -1.85 -3.17 -1.81 -1.75 ... ##  $ year.estimate     : num  -0.00912 0.0012 0.00158 0.00143 -0.00247 ... ##  $ intercept.stderror: num  0.1021 0.0861 0.1875 0.0848 0.0829 ... ##  $ year.stderror     : num  0.00684 0.00574 0.00973 0.00565 0.00554 ... ##  $ intercept.zvalue  : num  -22.4 -21.5 -16.9 -21.3 -21.1 ... ##  $ year.zvalue       : num  -1.334 0.208 0.163 0.253 -0.446 ... ##  $ intercept.pvalue  : num  1.70e-111 1.66e-102 6.54e-64 6.87e-101 1.06e-98 ... ##  $ year.pvalue       : num  0.182 0.835 0.871 0.8 0.656 ... ##  $ observations      : num  106 157 50 163 171 148 125 155 61 104 ... ##  - attr(*, \"intercept_year\")= num 1974 ##  - attr(*, \"min_year\")= num -24.5 ##  - attr(*, \"max_year\")= num 24.5 ##  - attr(*, \"nVisits\")= int 1155 ##  - attr(*, \"model_formula\")= chr \"cbind(successes, failures) ~ year + (1|site)\" ##  - attr(*, \"minL\")= num 2 ##  - attr(*, \"minTP\")= num 10 # We can plot these and see that we get different results to our # previous analysis since this time the method includes subsetting with(WSS_out[1:10,],      # Plot graph      {plot(x = 1:10, y = year.estimate,            ylim = range(c(year.estimate - year.stderror,                           year.estimate + year.stderror)),            ylab = 'Year effect (+/- Std Dev)',            xlab = 'Species',            xaxt=\"n\")      # Add x-axis with species names      axis(1, at=1:10, labels = species_name[1:10])      # Add the error bars      arrows(1:10, year.estimate - year.stderror,             1:10, year.estimate + year.stderror,             length=0.05, angle=90, code=3)}      )"},{"path":"/articles/vignette.html","id":"occupancy-models","dir":"Articles","previous_headings":"Modelling methods","what":"Occupancy models","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Occupancy models found Isaac et al (2014) one best tools analysing species occurrence data typical citizen science projects, robust powerful. method models occupancy process separately detection process, go details model since growing literature occupancy models, used. focus occupancy model discussed Isaac et al 2014 implemented sparta. function works similar fashion previous functions discussed. data takes ‘, , ’ functions, however option specify species wish model. feature added occupancy models computationally intensive. parameters function allow control number iterations, burnin, thinning, number chains, seed advanced users also possibility pass BUGS script.  run small example reality models usually run many thousands iterations, making analysis handful species impractical. access necessary facilities possible parallelise across species. use pair functions used internally occDetModel. formatOccData used format occurrence data format needed JAGS, occDetFunc, function undertakes modelling. formatOccData returns list length 2; first element ‘spp_vis’ data.frame visit (unique combination site time period) first column taxa following columns. Values taxa columns either TRUE FALSE depending whether observed visit. second element (‘occDetData’) data frame giving site, list length (number species observed visit) year visit. data correct format can now go modelling function  approach can used cluster computers, can hundreds processors, dramatically reduce run times.","code":"# Here is our data str(myData) ## 'data.frame':    8000 obs. of  4 variables: ##  $ taxa       : chr  \"r\" \"v\" \"e\" \"z\" ... ##  $ site       : chr  \"A51\" \"A87\" \"A56\" \"A28\" ... ##  $ time_period: Date, format: \"1970-01-14\" \"1980-09-29\" ... ##  $ tp         : int  3 4 5 1 3 5 4 1 5 4 ... # Run an occupancy model for three species # Here we use very small number of iterations  # to avoid a long run time system.time({ occ_out <- occDetModel(taxa = myData$taxa,                        site = myData$site,                        survey = myData$time_period,                        species_list = c('a','b','c','d'),                        write_results = FALSE,                        n_iterations = 200,                        burnin = 15,                        n_chains = 3,                        thinning = 3,                        seed = 123) }) ## Warning in errorChecks(taxa = taxa, site = site, survey = survey, replicate = ## replicate, : 94 out of 8000 observations will be removed as duplicates ##  ## ### ## Modeling a - 1 of 4 taxa ## #### PLEASE REVIEW THE BELOW #### ##  ## Your model settings: sparta, contlistlength ##  ## Model File: ##  ## model{ ##  ####################################### ## # SPARTA model from GitHub 26/05/2016 # ##  ## # State model ## for (i in 1:nsite){  ##   for (t in 1:nyear){    ##     z[i,t] ~ dbern(muZ[i,t])  ##     logit(muZ[i,t])<- a[t] + eta[i]  ##   }}   ##  ## # Priors  ## # State model priors ## for(t in 1:nyear){ ##   a[t] ~ dunif(-10,10)    ## }                  ##  ## # RANDOM EFFECT for SITE ## for (i in 1:nsite) { ##   eta[i] ~ dnorm(0, tau2)        ## }  ##  ## tau2 <- 1/(sigma2 * sigma2)  ## sigma2 ~ dunif(0, 5) ##  ##  ## # Observation model priors  ## for (t in 1:nyear) { ##   alpha.p[t] ~ dnorm(mu.lp, tau.lp)             ## } ##  ## mu.lp ~ dnorm(0, 0.01)                          ## tau.lp <- 1 / (sd.lp * sd.lp)                  ## sd.lp ~ dunif(0, 5)    ##  ## # Derived parameters state model ##  ## # Finite sample occupancy ## for (t in 1:nyear) {   ##   psi.fs[t] <- sum(z[1:nsite,t])/nsite ## }  LL.p ~ dunif(dtype2p_min, dtype2p_max) ## ### Observation Model ## for(j in 1:nvisit) { ##   y[j] ~ dbern(Py[j]) ##   Py[j]<- z[Site[j],Year[j]]*p[j] ##   logit(p[j]) <-  alpha.p[Year[j]] + LL.p*logL[j] ## } } ##  ## bugs_data: ##  ## List of 9 ##  $ y          : num [1:6211] 0 0 0 0 0 0 0 0 0 0 ... ##  $ Year       : num [1:6211] 3 7 10 11 12 12 13 14 16 19 ... ##  $ Site       : int [1:6211] 4 4 4 4 4 4 4 4 4 4 ... ##  $ nyear      : num 50 ##  $ nsite      : int 100 ##  $ nvisit     : int 6211 ##  $ logL       : num [1:6211] 0.693 0 0 0.693 0 ... ##  $ dtype2p_min: num -10 ##  $ dtype2p_max: num 10 ##  ##  ## init.vals: ##  ## List of 3 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 1 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] -0.85 -0.85 -0.85 -0.85 -0.85 ... ##   ..$ a      : num [1:50] 1.15 1.15 1.15 1.15 1.15 ... ##   ..$ eta    : num [1:100] -0.364 -0.364 -0.364 -0.364 -0.364 ... ##   ..$ LL.p   : num 1.53 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 1 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 1.76 1.76 1.76 1.76 1.76 ... ##   ..$ a      : num [1:50] -1.82 -1.82 -1.82 -1.82 -1.82 ... ##   ..$ eta    : num [1:100] 0.112 0.112 0.112 0.112 0.112 ... ##   ..$ LL.p   : num 1.57 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 1 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 0.206 0.206 0.206 0.206 0.206 ... ##   ..$ a      : num [1:50] -0.174 -0.174 -0.174 -0.174 -0.174 ... ##   ..$ eta    : num [1:100] 1.83 1.83 1.83 1.83 1.83 ... ##   ..$ LL.p   : num -0.187 ##  ##  ## parameters: ##  ## psi.fs tau2 tau.lp alpha.p a mu.lp LL.p ## module glm loaded ## Compiling model graph ##    Resolving undeclared variables ##    Allocating nodes ## Graph information: ##    Observed stochastic nodes: 6211 ##    Unobserved stochastic nodes: 5204 ##    Total graph size: 44866 ##  ## Initializing model ##  ##  ## ### ## Modeling b - 2 of 4 taxa ## #### PLEASE REVIEW THE BELOW #### ##  ## Your model settings: sparta, contlistlength ##  ## Model File: ##  ## model{ ##  ####################################### ## # SPARTA model from GitHub 26/05/2016 # ##  ## # State model ## for (i in 1:nsite){  ##   for (t in 1:nyear){    ##     z[i,t] ~ dbern(muZ[i,t])  ##     logit(muZ[i,t])<- a[t] + eta[i]  ##   }}   ##  ## # Priors  ## # State model priors ## for(t in 1:nyear){ ##   a[t] ~ dunif(-10,10)    ## }                  ##  ## # RANDOM EFFECT for SITE ## for (i in 1:nsite) { ##   eta[i] ~ dnorm(0, tau2)        ## }  ##  ## tau2 <- 1/(sigma2 * sigma2)  ## sigma2 ~ dunif(0, 5) ##  ##  ## # Observation model priors  ## for (t in 1:nyear) { ##   alpha.p[t] ~ dnorm(mu.lp, tau.lp)             ## } ##  ## mu.lp ~ dnorm(0, 0.01)                          ## tau.lp <- 1 / (sd.lp * sd.lp)                  ## sd.lp ~ dunif(0, 5)    ##  ## # Derived parameters state model ##  ## # Finite sample occupancy ## for (t in 1:nyear) {   ##   psi.fs[t] <- sum(z[1:nsite,t])/nsite ## }  LL.p ~ dunif(dtype2p_min, dtype2p_max) ## ### Observation Model ## for(j in 1:nvisit) { ##   y[j] ~ dbern(Py[j]) ##   Py[j]<- z[Site[j],Year[j]]*p[j] ##   logit(p[j]) <-  alpha.p[Year[j]] + LL.p*logL[j] ## } } ##  ## bugs_data: ##  ## List of 9 ##  $ y          : num [1:6211] 0 0 0 0 0 0 0 0 0 0 ... ##  $ Year       : num [1:6211] 3 7 10 11 12 12 13 14 16 19 ... ##  $ Site       : int [1:6211] 4 4 4 4 4 4 4 4 4 4 ... ##  $ nyear      : num 50 ##  $ nsite      : int 100 ##  $ nvisit     : int 6211 ##  $ logL       : num [1:6211] 0.693 0 0 0.693 0 ... ##  $ dtype2p_min: num -10 ##  $ dtype2p_max: num 10 ##  ##  ## init.vals: ##  ## List of 3 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] -0.85 -0.85 -0.85 -0.85 -0.85 ... ##   ..$ a      : num [1:50] 1.15 1.15 1.15 1.15 1.15 ... ##   ..$ eta    : num [1:100] -0.364 -0.364 -0.364 -0.364 -0.364 ... ##   ..$ LL.p   : num 1.53 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 1.76 1.76 1.76 1.76 1.76 ... ##   ..$ a      : num [1:50] -1.82 -1.82 -1.82 -1.82 -1.82 ... ##   ..$ eta    : num [1:100] 0.112 0.112 0.112 0.112 0.112 ... ##   ..$ LL.p   : num 1.57 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 0.206 0.206 0.206 0.206 0.206 ... ##   ..$ a      : num [1:50] -0.174 -0.174 -0.174 -0.174 -0.174 ... ##   ..$ eta    : num [1:100] 1.83 1.83 1.83 1.83 1.83 ... ##   ..$ LL.p   : num -0.187 ##  ##  ## parameters: ##  ## psi.fs tau2 tau.lp alpha.p a mu.lp LL.pCompiling model graph ##    Resolving undeclared variables ##    Allocating nodes ## Graph information: ##    Observed stochastic nodes: 6211 ##    Unobserved stochastic nodes: 5204 ##    Total graph size: 44866 ##  ## Initializing model ##  ##  ## ### ## Modeling c - 3 of 4 taxa ## #### PLEASE REVIEW THE BELOW #### ##  ## Your model settings: sparta, contlistlength ##  ## Model File: ##  ## model{ ##  ####################################### ## # SPARTA model from GitHub 26/05/2016 # ##  ## # State model ## for (i in 1:nsite){  ##   for (t in 1:nyear){    ##     z[i,t] ~ dbern(muZ[i,t])  ##     logit(muZ[i,t])<- a[t] + eta[i]  ##   }}   ##  ## # Priors  ## # State model priors ## for(t in 1:nyear){ ##   a[t] ~ dunif(-10,10)    ## }                  ##  ## # RANDOM EFFECT for SITE ## for (i in 1:nsite) { ##   eta[i] ~ dnorm(0, tau2)        ## }  ##  ## tau2 <- 1/(sigma2 * sigma2)  ## sigma2 ~ dunif(0, 5) ##  ##  ## # Observation model priors  ## for (t in 1:nyear) { ##   alpha.p[t] ~ dnorm(mu.lp, tau.lp)             ## } ##  ## mu.lp ~ dnorm(0, 0.01)                          ## tau.lp <- 1 / (sd.lp * sd.lp)                  ## sd.lp ~ dunif(0, 5)    ##  ## # Derived parameters state model ##  ## # Finite sample occupancy ## for (t in 1:nyear) {   ##   psi.fs[t] <- sum(z[1:nsite,t])/nsite ## }  LL.p ~ dunif(dtype2p_min, dtype2p_max) ## ### Observation Model ## for(j in 1:nvisit) { ##   y[j] ~ dbern(Py[j]) ##   Py[j]<- z[Site[j],Year[j]]*p[j] ##   logit(p[j]) <-  alpha.p[Year[j]] + LL.p*logL[j] ## } } ##  ## bugs_data: ##  ## List of 9 ##  $ y          : num [1:6211] 0 0 0 0 0 0 0 0 0 0 ... ##  $ Year       : num [1:6211] 3 7 10 11 12 12 13 14 16 19 ... ##  $ Site       : int [1:6211] 4 4 4 4 4 4 4 4 4 4 ... ##  $ nyear      : num 50 ##  $ nsite      : int 100 ##  $ nvisit     : int 6211 ##  $ logL       : num [1:6211] 0.693 0 0 0.693 0 ... ##  $ dtype2p_min: num -10 ##  $ dtype2p_max: num 10 ##  ##  ## init.vals: ##  ## List of 3 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 1 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] -0.85 -0.85 -0.85 -0.85 -0.85 ... ##   ..$ a      : num [1:50] 1.15 1.15 1.15 1.15 1.15 ... ##   ..$ eta    : num [1:100] -0.364 -0.364 -0.364 -0.364 -0.364 ... ##   ..$ LL.p   : num 1.53 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 1 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 1.76 1.76 1.76 1.76 1.76 ... ##   ..$ a      : num [1:50] -1.82 -1.82 -1.82 -1.82 -1.82 ... ##   ..$ eta    : num [1:100] 0.112 0.112 0.112 0.112 0.112 ... ##   ..$ LL.p   : num 1.57 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 1 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 0.206 0.206 0.206 0.206 0.206 ... ##   ..$ a      : num [1:50] -0.174 -0.174 -0.174 -0.174 -0.174 ... ##   ..$ eta    : num [1:100] 1.83 1.83 1.83 1.83 1.83 ... ##   ..$ LL.p   : num -0.187 ##  ##  ## parameters: ##  ## psi.fs tau2 tau.lp alpha.p a mu.lp LL.pCompiling model graph ##    Resolving undeclared variables ##    Allocating nodes ## Graph information: ##    Observed stochastic nodes: 6211 ##    Unobserved stochastic nodes: 5204 ##    Total graph size: 44866 ##  ## Initializing model ##  ##  ## ### ## Modeling d - 4 of 4 taxa ## #### PLEASE REVIEW THE BELOW #### ##  ## Your model settings: sparta, contlistlength ##  ## Model File: ##  ## model{ ##  ####################################### ## # SPARTA model from GitHub 26/05/2016 # ##  ## # State model ## for (i in 1:nsite){  ##   for (t in 1:nyear){    ##     z[i,t] ~ dbern(muZ[i,t])  ##     logit(muZ[i,t])<- a[t] + eta[i]  ##   }}   ##  ## # Priors  ## # State model priors ## for(t in 1:nyear){ ##   a[t] ~ dunif(-10,10)    ## }                  ##  ## # RANDOM EFFECT for SITE ## for (i in 1:nsite) { ##   eta[i] ~ dnorm(0, tau2)        ## }  ##  ## tau2 <- 1/(sigma2 * sigma2)  ## sigma2 ~ dunif(0, 5) ##  ##  ## # Observation model priors  ## for (t in 1:nyear) { ##   alpha.p[t] ~ dnorm(mu.lp, tau.lp)             ## } ##  ## mu.lp ~ dnorm(0, 0.01)                          ## tau.lp <- 1 / (sd.lp * sd.lp)                  ## sd.lp ~ dunif(0, 5)    ##  ## # Derived parameters state model ##  ## # Finite sample occupancy ## for (t in 1:nyear) {   ##   psi.fs[t] <- sum(z[1:nsite,t])/nsite ## }  LL.p ~ dunif(dtype2p_min, dtype2p_max) ## ### Observation Model ## for(j in 1:nvisit) { ##   y[j] ~ dbern(Py[j]) ##   Py[j]<- z[Site[j],Year[j]]*p[j] ##   logit(p[j]) <-  alpha.p[Year[j]] + LL.p*logL[j] ## } } ##  ## bugs_data: ##  ## List of 9 ##  $ y          : num [1:6211] 0 0 0 0 0 0 0 0 0 0 ... ##  $ Year       : num [1:6211] 3 7 10 11 12 12 13 14 16 19 ... ##  $ Site       : int [1:6211] 4 4 4 4 4 4 4 4 4 4 ... ##  $ nyear      : num 50 ##  $ nsite      : int 100 ##  $ nvisit     : int 6211 ##  $ logL       : num [1:6211] 0.693 0 0 0.693 0 ... ##  $ dtype2p_min: num -10 ##  $ dtype2p_max: num 10 ##  ##  ## init.vals: ##  ## List of 3 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] -0.85 -0.85 -0.85 -0.85 -0.85 ... ##   ..$ a      : num [1:50] 1.15 1.15 1.15 1.15 1.15 ... ##   ..$ eta    : num [1:100] -0.364 -0.364 -0.364 -0.364 -0.364 ... ##   ..$ LL.p   : num 1.53 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 1.76 1.76 1.76 1.76 1.76 ... ##   ..$ a      : num [1:50] -1.82 -1.82 -1.82 -1.82 -1.82 ... ##   ..$ eta    : num [1:100] 0.112 0.112 0.112 0.112 0.112 ... ##   ..$ LL.p   : num 1.57 ##  $ :List of 5 ##   ..$ z      : num [1:100, 1:50] 0 0 0 0 0 0 0 0 0 0 ... ##   .. ..- attr(*, \"dimnames\")=List of 2 ##   .. .. ..$ : chr [1:100] \"1\" \"2\" \"3\" \"4\" ... ##   .. .. ..$ : chr [1:50] \"1950\" \"1951\" \"1952\" \"1953\" ... ##   ..$ alpha.p: num [1:50] 0.206 0.206 0.206 0.206 0.206 ... ##   ..$ a      : num [1:50] -0.174 -0.174 -0.174 -0.174 -0.174 ... ##   ..$ eta    : num [1:100] 1.83 1.83 1.83 1.83 1.83 ... ##   ..$ LL.p   : num -0.187 ##  ##  ## parameters: ##  ## psi.fs tau2 tau.lp alpha.p a mu.lp LL.pCompiling model graph ##    Resolving undeclared variables ##    Allocating nodes ## Graph information: ##    Observed stochastic nodes: 6211 ##    Unobserved stochastic nodes: 5204 ##    Total graph size: 44866 ##  ## Initializing model ##    user  system elapsed  ##   45.59    0.39   46.81 # Lets look at the results ## The object returned is a list with one element for each species names(occ_out) ## [1] \"a\" \"b\" \"c\" \"d\" # Each of these is an object of class 'occDet' class(occ_out$a) ## [1] \"occDet\" # Inside these elements is the information of interest names(occ_out$a) ##  [1] \"model\"                \"BUGSoutput\"           \"parameters.to.save\"   ##  [4] \"model.file\"           \"n.iter\"               \"DIC\"                  ##  [7] \"SPP_NAME\"             \"min_year\"             \"max_year\"             ## [10] \"sites_included\"       \"nsites\"               \"nvisits\"              ## [13] \"species_observations\" \"sparta_version\" # Of particular interest to many users will be the summary # data in the BUGSoutput head(occ_out$a$BUGSoutput$summary) ##            mean        sd       2.5%        25%        50%       75%    97.5% ## LL.p  0.6884513 0.3656048 -0.1697022  0.4587780  0.7107760 0.9515777 1.314354 ## a[1]  3.8286967 4.0973899 -2.0682831 -0.4701006  4.8973219 7.5259563 9.648971 ## a[2]  3.0109148 4.5299601 -4.2889715 -1.5499812  3.8631497 7.0459116 9.692108 ## a[3]  2.1243340 4.5400542 -5.6648288 -2.3828239  3.3304320 5.7827284 9.255716 ## a[4]  0.2466571 3.3156570 -5.2388938 -2.5060233  0.3879172 2.1154343 7.557222 ## a[5] -0.8585953 1.8288804 -3.8219025 -2.0175067 -1.2281131 0.1739051 3.332545 ##          Rhat n.eff ## LL.p 1.279623    12 ## a[1] 2.890550     4 ## a[2] 2.516427     4 ## a[3] 3.203373     4 ## a[4] 2.672485     4 ## a[5] 1.121937    24 # We have included a plotting feature for objects of class # occDet which provides a useful visualisation of the trend # in occupancy over time plot(occ_out$a) # First format our data formattedOccData <- formatOccData(taxa = myData$taxa,                                   site = myData$site,                                   survey = myData$time_period) ## Warning in errorChecks(taxa = taxa, site = site, survey = survey, replicate = ## replicate, : 94 out of 8000 observations will be removed as duplicates # This is a list of two elements names(formattedOccData) ## [1] \"spp_vis\"    \"occDetdata\" # Lets have a look at spp_vis head(formattedOccData$spp_vis[,1:5]) ##             visit     a     b     c     d ## 1 A1001950-01-041 FALSE FALSE FALSE FALSE ## 2 A1001950-11-011  TRUE FALSE FALSE FALSE ## 3 A1001951-08-251 FALSE FALSE FALSE FALSE ## 4 A1001951-11-031 FALSE FALSE FALSE FALSE ## 5 A1001952-02-071 FALSE FALSE FALSE FALSE ## 6 A1001953-02-221 FALSE FALSE FALSE FALSE # Lets have a look at occDetData head(formattedOccData$occDetdata) ##             visit site L   TP ## 1 A1001950-01-041 A100 2 1950 ## 3 A1001950-11-011 A100 1 1950 ## 4 A1001951-08-251 A100 1 1951 ## 5 A1001951-11-031 A100 1 1951 ## 6 A1001952-02-071 A100 1 1952 ## 7 A1001953-02-221 A100 1 1953 # Use the occupancy modelling function to parrellise the process # Here we are going to use the package snowfall library(snowfall)  # I have 4 cpus on my PC so I set cpus to 4 # when I initialise the cluster sfInit(parallel = TRUE, cpus = 4) ## snowfall 1.84-6.3 initialized (using snow 0.4-4): parallel execution on 4 CPUs. # Export my data to the cluster sfExport('formattedOccData')  # I create a function that takes a species name and runs my model occ_mod_function <- function(taxa_name){      library(sparta)      occ_out <- occDetFunc(taxa_name = taxa_name,                         n_iterations = 200,                         burnin = 15,                          occDetdata = formattedOccData$occDetdata,                         spp_vis = formattedOccData$spp_vis,                         write_results = FALSE,                         seed = 123)   }   # I then run this in parallel system.time({ para_out <- sfClusterApplyLB(c('a','b','c','d'), occ_mod_function) }) ##    user  system elapsed  ##    0.01    0.02   16.41 # Name each element of this output by the species for(i in  1:length(para_out)) names(para_out)[i] <- para_out[[i]]$SPP_NAM  # Stop the cluster sfStop() ##  ## Stopping cluster # This takes about half the time of the  # serial version we ran earlier, and the resulting object  # is the same (since we set the random seed to be the same # in each) head(para_out$a$BUGSoutput$summary) ##            mean        sd       2.5%        25%        50%       75%    97.5% ## LL.p  0.6884513 0.3656048 -0.1697022  0.4587780  0.7107760 0.9515777 1.314354 ## a[1]  3.8286967 4.0973899 -2.0682831 -0.4701006  4.8973219 7.5259563 9.648971 ## a[2]  3.0109148 4.5299601 -4.2889715 -1.5499812  3.8631497 7.0459116 9.692108 ## a[3]  2.1243340 4.5400542 -5.6648288 -2.3828239  3.3304320 5.7827284 9.255716 ## a[4]  0.2466571 3.3156570 -5.2388938 -2.5060233  0.3879172 2.1154343 7.557222 ## a[5] -0.8585953 1.8288804 -3.8219025 -2.0175067 -1.2281131 0.1739051 3.332545 ##          Rhat n.eff ## LL.p 1.279623    12 ## a[1] 2.890550     4 ## a[2] 2.516427     4 ## a[3] 3.203373     4 ## a[4] 2.672485     4 ## a[5] 1.121937    24 plot(para_out$a)"},{"path":"/articles/vignette.html","id":"frescalo","dir":"Articles","previous_headings":"Modelling methods","what":"Frescalo","title":"sparta - Species Presence/Absence R Trends Analyses","text":"frescalo method outlined Hill (2012) means account spatial temporal bias. method shown Isaac et al (2014) good method data aggregated time periods comparing atlases. frescalo method run using .exe, need download file visiting link - https://github.com/BiologicalRecordsCentre/frescalo. downloaded .exe make note directory placed , need moment. assume data ‘, , ’ format similar used previous method: Frescalo’s requirements terms data structure types little different seen functions. Firstly entire data.frame passed argument called Data, column names various elements (taxa, site, etc) given arguments. Secondly frescalo requires ‘’ component either column year two columns, one ‘start date’ one ‘end date’. data presented fit format first must reformat . situation simplest thing add column giving year. Since frescalo aggregates across time periods (often decades greater) loss temporal resolution issue. Now data correct format frescalo one major component need, weights file. can find weights file used original paper (Hill, 2012). short weights file outlines similarity sites dataset. information used weight analysis site accordingly. undertaking analysis UK 10km square resolution built weights files can use. weights files use UK landcover map instead floristic similarity (used Hill (2012)). can find frescalo help file. sake demonstration let us assume weights file analysis, want create . create weights file need two things, measure physical distance sites measure similarity. original paper similarity measure floristic similarity, also habitat similarity whatever relevant taxa studying. example table distances land cover proportions site createWeights function follows procedure outlined Hill (2012) creating weights information can found help file function. data weights file now ready proceed frescalo. functions frescalo can take range additional arguments can see entering ?frescalo console, minimal example. get warning analysis value phi low. case simulated data suggests every species found every site time periods. little unrealistic get similar warning data might want consult Hill (2012) change input value phi. object returned (frescalo_results case) object class frescalo. means couple special methods can use . results frescalo may seem complex first suggest reading Value section frescalo help file details. brief: frescalo_results$paths lists file paths raw data files $log, $stat, $freq $trend, order. frescalo_results$trend data.frame providing list time factors (measure probability occurrence relative benchmark species) species-timeperiod. frescalo_results$stat data.frame giving details sites estimated species richness. frescalo_results$freq data.frame species frequencies, probabilities species present certain location. frescalo_results$log, simple report console output .exe. frescalo_results$lm_stats data.frame giving results linear regression Tfactors species two time periods used. 2 time periods used (example) linear modeling section data.frame filled NAs z-test performed instead (results given last columns). data UK sites given grid referenes functionality plot simple output results worth noting console output . get warning telling us data site weights file, might want investigate add site weights file. ignore now. second warning tells us sinkdir gave already frescalo output . function got around renaming output. finally got long list species data compiled internally. Now plotting.  panel plot gives different information results. top left plot shows observed number species site (given unicorn_results$stat$No_spp), can contrasted top right plot gives estimated number species accounting recording effort (given unicorn_results$stat$Spnum_out). Recording effort presented bottom left panel - low values alpha (white) show areas high recording effort (given unicorn_results$stat$Alpha), summary species trends given bottom right (given unicorn_results$lm_stats). case skew towards species increasing, however may non-significant, explored detail referring unicorn_results$lm_stats.","code":"head(myData) ##   taxa site time_period tp ## 1    r  A51  1970-01-14  3 ## 2    v  A87  1980-09-29  4 ## 3    e  A56  1996-04-14  5 ## 4    z  A28  1959-01-16  1 ## 5    r  A77  1970-09-21  3 ## 6    x  A48  1990-02-25  5 # Add a year column myData$year <- as.numeric(format(myData$time_period, '%Y')) head(myData) ##   taxa site time_period tp year ## 1    r  A51  1970-01-14  3 1970 ## 2    v  A87  1980-09-29  4 1980 ## 3    e  A56  1996-04-14  5 1996 ## 4    z  A28  1959-01-16  1 1959 ## 5    r  A77  1970-09-21  3 1970 ## 6    x  A48  1990-02-25  5 1990 # Here is the distance table head(myDistances) ##     x   y     dist ## 1 A51 A51    0.000 ## 2 A87 A51 1650.470 ## 3 A56 A51 7705.637 ## 4 A28 A51 7354.491 ## 5 A77 A51 9719.038 ## 6 A48 A51 4670.059 # Here is our habitat data head(myHabitatData) ##   site grassland    woodland  heathland      urban   freshwater ## 1  A51 0.3635466 0.327223138 0.09360757 0.21535377 0.0002689656 ## 2  A87 0.2383334 0.139465479 0.19703582 0.19958681 0.2255784967 ## 3  A56 0.1528755 0.102810832 0.54454910 0.09993444 0.0998301313 ## 4  A28 0.2263529 0.163973437 0.37379008 0.22376859 0.0121149659 ## 5  A77 0.1226620 0.007872836 0.24780359 0.29819699 0.3234645983 ## 6  A48 0.3693481 0.183664806 0.21905837 0.07665786 0.1512709139 # With our distance and habitat tables in hand we can # use the createWeights function to build our weights file # I have changed the defualts of dist_sub and sim_sub since # we have a very small example dataset of only 50 sites myWeights <- createWeights(distances = myDistances,                            attributes = myHabitatData,                            dist_sub = 20,                            sim_sub = 10) ## Creating similarity distance table...Complete ## Creating weights file... ## 0% ##   |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  17%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  23%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  40%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  77%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================| 100% ## Complete head(myWeights) ##   target neighbour weight ## 1    A51      A100 0.0000 ## 2    A51       A13 0.0618 ## 3    A51       A27 0.0835 ## 4    A51       A36 0.1425 ## 5    A51       A40 0.9510 ## 6    A51       A44 0.0763 # First we need to enter the location where we placed the .exe # In my case I saved it to a folder within the source package directory. Note that this installer has been filtered out in the .gitignore to reduce size, and therefore you will need to install it separately myFrescaloPath <- file.path(getwd(), \"vignette_frescalo.exe\")  # I then want to set up the time periods I want to analyse # Here I say I want to compare 1980-89 to 1990-99 myTimePeriods <- data.frame(start = c(1980, 1990), end = c(1989, 1999)) head(myTimePeriods) ##   start  end ## 1  1980 1989 ## 2  1990 1999 # I also need to specify where I want my results to be saved # I'm going to save it in a folder in my working directory myFolder <- 'myFolder'  # Simple run of frescalo frescalo_results <- frescalo(Data = myData,                               frespath = myFrescaloPath,                              time_periods = myTimePeriods,                              site_col = 'site',                              sp_col = 'taxa',                              year = 'year',                              Fres_weights = myWeights,                              sinkdir = myFolder) ##  ## SAVING DATA TO FRESCALO WORKING DIRECTORY ## ******************** ##  ##  ## RUNNING FRESCALO ## ******************** ## Warning in run_fresc_file(fres_data = Data, output_dir = fresoutput, ## frescalo_path = frespath, : Your value of phi (0.74) is smaller than the 98.5 ## percentile of input phi (0.89). It is reccommended your phi be similar to this ## value. For more information see Hill (2011) reference in frescalo help file ## Building Species List - Complete ## Outputting Species Results ##  Species 1 of 26 - a - 05/06/2024 15:33:12 ##  Species 2 of 26 - b - 05/06/2024 15:33:12 ##  Species 3 of 26 - c - 05/06/2024 15:33:12 ##  Species 4 of 26 - d - 05/06/2024 15:33:12 ##  Species 5 of 26 - e - 05/06/2024 15:33:12 ##  Species 6 of 26 - f - 05/06/2024 15:33:12 ##  Species 7 of 26 - g - 05/06/2024 15:33:12 ##  Species 8 of 26 - h - 05/06/2024 15:33:12 ##  Species 9 of 26 - i - 05/06/2024 15:33:12 ##  Species 10 of 26 - j - 05/06/2024 15:33:12 ##  Species 11 of 26 - k - 05/06/2024 15:33:12 ##  Species 12 of 26 - l - 05/06/2024 15:33:12 ##  Species 13 of 26 - m - 05/06/2024 15:33:12 ##  Species 14 of 26 - n - 05/06/2024 15:33:12 ##  Species 15 of 26 - o - 05/06/2024 15:33:12 ##  Species 16 of 26 - p - 05/06/2024 15:33:12 ##  Species 17 of 26 - q - 05/06/2024 15:33:12 ##  Species 18 of 26 - r - 05/06/2024 15:33:12 ##  Species 19 of 26 - s - 05/06/2024 15:33:12 ##  Species 20 of 26 - t - 05/06/2024 15:33:12 ##  Species 21 of 26 - u - 05/06/2024 15:33:12 ##  Species 22 of 26 - v - 05/06/2024 15:33:12 ##  Species 23 of 26 - w - 05/06/2024 15:33:12 ##  Species 24 of 26 - x - 05/06/2024 15:33:12 ##  Species 25 of 26 - y - 05/06/2024 15:33:12 ##  Species 26 of 26 - z - 05/06/2024 15:33:12 ## [1] \"frescalo complete\" # Using 'summary' gives a quick overview of our data # This can be useful to double check that your data was read in correctly summary(frescalo_results) ##  Actual numbers in data  ##      Number of samples           100  ##      Number of species            26  ##      Number of time periods        2  ##      Number of observations     2239  ##      Neighbourhood weights      1000  ##      Benchmark exclusions          0  ##      Filter locations included     0 # Using 'print' we get a preview of the results print(frescalo_results) ##  ## Preview of $paths - file paths to frescalo log, stats, freq, trend .csv files: ##  ## [1] \"myFolder/frescalo_240605/Output/Log.txt\"            ## [2] \"myFolder/frescalo_240605/Output/Stats.csv\"          ## [3] \"myFolder/frescalo_240605/Output/Freq.csv\"           ## [4] \"myFolder/frescalo_240605/Output/Trend.csv\"          ## [5] \"myFolder/frescalo_240605/Output/Freq_quickload.txt\" ##  ##  ## Preview of $trend - trends file, giving the tfactor value for each species at each time period: ##  ##   Species   Time TFactor StDev  X Xspt Xest N.0.00 N.0.98 ## 1       a 1984.5   0.466 0.174  8    8    8     90      0 ## 2       a 1994.5   1.098 0.300 17   16   16     90      0 ## 3       j 1984.5   1.173 0.202 46   46   46    100      1 ## 4       j 1994.5   0.774 0.144 35   34   34    100      0 ## 5       k 1984.5   0.939 0.163 44   43   43    100      1 ## 6       k 1994.5   0.977 0.173 46   46   46    100      3 ##  ##  ## Preview of $stat - statistics for each hectad in the analysis: ##  ##   Location Loc_no No_spp Phi_in Alpha Wgt_n2 Phi_out Spnum_in Spnum_out Iter ## 1       A1      1     11  0.646  1.62   3.65    0.74     12.6      15.8    8 ## 2      A10      2     13  0.748  0.95   3.49    0.74     16.2      15.9    4 ## 3     A100      3     18  0.883  0.27   1.92    0.74     18.3      12.6    6 ## 4      A11      4     16  0.752  0.94   2.87    0.74     15.7      15.4    6 ## 5      A12      5     11  0.752  0.90   3.86    0.74     15.1      14.6    3 ## 6      A13      6      8  0.636  1.80   3.03    0.74     12.6      16.4    5 ##  ##  ## Preview of $freq - rescaled frequencies for each location and species: ##  ##   Location Species Pres   Freq  Freq1 SDFrq1 Rank Rank1 ## 1       A1       v    1 1.0000 1.0000 0.0000    1 0.063 ## 2       A1       y    1 1.0000 1.0000 0.0000    2 0.127 ## 3       A1       i    1 0.9939 0.9997 0.0035    3 0.190 ## 4       A1       x    1 0.7181 0.8717 0.1683    4 0.253 ## 5       A1       w    1 0.7131 0.8680 0.1712    5 0.317 ## 6       A1       j    1 0.6924 0.8522 0.1831    6 0.380 ##  ##  ## Preview of $log - log file: ##  ##     Number of species            26 ##     Number of time periods        2 ##     Number of observations     2239 ##     Neighbourhood weights      1000 ##     Benchmark exclusions          0 ##     Filter locations included     0 ##  ##  ##  98.5 percentile of input phi  0.89 ##  Target value of phi           0.74 ##  ##  ##  ##  ## Preview of $lm_stats - trends in tfactor over time: ##  ##    SPECIES NAME       b          a b_std_err b_tval b_pval a_std_err a_tval ## 1       S1    a  0.0632 -124.95440        NA     NA     NA        NA     NA ## 12      S2    b -0.0001    1.03745        NA     NA     NA        NA     NA ## 20      S3    c  0.0122  -23.38590        NA     NA     NA        NA     NA ## 21      S4    d  0.0531 -104.58595        NA     NA     NA        NA     NA ## 22      S5    e  0.0042   -7.54590        NA     NA     NA        NA     NA ## 23      S6    f  0.0457  -89.92865        NA     NA     NA        NA     NA ##    a_pval adj_r2 r2 F_val F_num_df F_den_df   Ymin   Ymax        Z_VAL SIG_95 ## 1      NA     NA  1    NA        1        0 1984.5 1994.5  1.822332372  FALSE ## 12     NA     NA  1    NA        1        0 1984.5 1994.5 -0.003100868  FALSE ## 20     NA     NA  1    NA        1        0 1984.5 1994.5  0.400180719  FALSE ## 21     NA     NA  1    NA        1        0 1984.5 1994.5  1.592757123  FALSE ## 22     NA     NA  1    NA        1        0 1984.5 1994.5  0.155871253  FALSE ## 23     NA     NA  1    NA        1        0 1984.5 1994.5  1.609853664  FALSE # There is a lot of information here and you can read more about # what these data mean by looking at the frescalo help file # The files detailed in paths are also in the object returned frescalo_results$paths ## [1] \"myFolder/frescalo_240605/Output/Log.txt\"            ## [2] \"myFolder/frescalo_240605/Output/Stats.csv\"          ## [3] \"myFolder/frescalo_240605/Output/Freq.csv\"           ## [4] \"myFolder/frescalo_240605/Output/Trend.csv\"          ## [5] \"myFolder/frescalo_240605/Output/Freq_quickload.txt\" names(frescalo_results) ## [1] \"paths\"    \"trend\"    \"stat\"     \"freq\"     \"log\"      \"lm_stats\" # However we additionally get some model results in our returned object # under '$lm_stats' # Lets look at some results fo the first three species frescalo_results$lm_stats[1:3, c('NAME','Z_VAL','SIG_95')] ##    NAME        Z_VAL SIG_95 ## 1     a  1.822332372  FALSE ## 12    b -0.003100868  FALSE ## 20    c  0.400180719  FALSE # None of these have a significant change using a z-test # Lets look at the raw data frescalo_results$trend[frescalo_results$trend$Species %in% c('a', 'b', 'c'),                        c('Species', 'Time', 'TFactor', 'StDev')] ##    Species   Time TFactor StDev ## 1        a 1984.5   0.466 0.174 ## 2        a 1994.5   1.098 0.300 ## 23       b 1984.5   0.839 0.224 ## 24       b 1994.5   0.838 0.232 ## 39       c 1984.5   0.825 0.210 ## 40       c 1994.5   0.947 0.221 # We can see from these results that the big standard deviations on  # the tfactor values means there is no real difference between the  # two time periods # This only works with UK grid references # We can load an example dataset from the UK data(unicorns) head(unicorns) ##            start_date            end_date site    species ## 1 1990-08-29 08:13:12 1990-08-29 20:13:12 TQ79 Species 12 ## 2 1993-11-07 04:46:56 1993-11-07 09:46:56 TQ92 Species 17 ## 3 2007-03-16 05:47:11 2007-03-16 13:47:11 TV69  Species 5 ## 4 2008-01-08 11:24:01 2008-01-09 01:24:01 TR05 Species 17 ## 5 1974-08-03 13:24:42 1974-08-03 18:24:42 TR33 Species 13 ## 6 1989-12-08 13:16:45 1989-12-08 22:16:45 TQ93 Species 15 # Create a new time period range myTimePeriods <- data.frame(start= c(1968, 2001), end = c(2000, 2023))  # Now run frescalo using hte built in weights file unicorn_results <- frescalo(Data = unicorns,                              frespath = myFrescaloPath,                             time_periods = myTimePeriods,                             site_col = \"site\",                             sp_col = \"species\",                             start_col = \"start_date\",                             end_col = 'end_date',                             sinkdir = myFolder) ## Warning in frescalo(Data = unicorns, frespath = myFrescaloPath, time_periods = ## myTimePeriods, : sinkdir already contains frescalo output. New data saved in ## myFolder/frescalo_240605(1) ##  ## SAVING DATA TO FRESCALO WORKING DIRECTORY ## ******************** ##  ##  ## RUNNING FRESCALO ## ******************** ## Warning in run_fresc_file(fres_data = Data, output_dir = fresoutput, ## frescalo_path = frespath, : -1.#J phi value calculated ## Building Species List - Complete ## Outputting Species Results ##  Species 1 of 20 - Species 1 - 05/06/2024 15:33:31 ##  Species 2 of 20 - Species 10 - 05/06/2024 15:33:31 ##  Species 3 of 20 - Species 11 - 05/06/2024 15:33:31 ##  Species 4 of 20 - Species 12 - 05/06/2024 15:33:31 ##  Species 5 of 20 - Species 13 - 05/06/2024 15:33:31 ##  Species 6 of 20 - Species 14 - 05/06/2024 15:33:31 ##  Species 7 of 20 - Species 15 - 05/06/2024 15:33:31 ##  Species 8 of 20 - Species 16 - 05/06/2024 15:33:31 ##  Species 9 of 20 - Species 17 - 05/06/2024 15:33:31 ##  Species 10 of 20 - Species 18 - 05/06/2024 15:33:31 ##  Species 11 of 20 - Species 19 - 05/06/2024 15:33:31 ##  Species 12 of 20 - Species 2 - 05/06/2024 15:33:31 ##  Species 13 of 20 - Species 20 - 05/06/2024 15:33:31 ##  Species 14 of 20 - Species 3 - 05/06/2024 15:33:31 ##  Species 15 of 20 - Species 4 - 05/06/2024 15:33:31 ##  Species 16 of 20 - Species 5 - 05/06/2024 15:33:31 ##  Species 17 of 20 - Species 6 - 05/06/2024 15:33:31 ##  Species 18 of 20 - Species 7 - 05/06/2024 15:33:31 ##  Species 19 of 20 - Species 8 - 05/06/2024 15:33:31 ##  Species 20 of 20 - Species 9 - 05/06/2024 15:33:31 ## [1] \"frescalo complete\" plot(unicorn_results)"},{"path":"/articles/vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"sparta - Species Presence/Absence R Trends Analyses","text":"Hill, M.O. (2012) Local frequency key interpreting species occurrence data recording effort known. Methods Ecol. Evol. 3, 195-205 Isaac, N.J.B. et al. (2014) Statistics citizen science: extracting signals change noisy ecological data. Methods Ecol. Evol. 5, 1052-1060 Roy, H.E. et al. (2012) Invasive alien predator causes rapid declines native European ladybirds. Divers. Distrib. 18, 717-725 Telfer, M.G. et al. (2002) general method measuring relative change range size biological atlas data. Biol. Conserv. 107, 99-109 Thomas, J.. et al. (2015) Recent trends UK insects inhabit early successional stages ecosystems. Biol. J. Linn. Soc. 115, 636-646","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nick Isaac. Author. Tom August. Author. Dylan Carbone. Author, maintainer. Colin Harrower. Author. Jack Hatfield. Author. Mark Hill. Author. Francesca Mancini. Author. Charlie Outhwaite. Author. Gary Powney. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Isaac N, August T, Carbone D, Harrower C, Hatfield J, Hill M, Mancini F, Outhwaite C, Powney G (2024). sparta: Trend Analysis Unstructured Data. R package version 0.2.19, https://github.com/BiologicalRecordsCentre/sparta.","code":"@Manual{,   title = {sparta: Trend Analysis for Unstructured Data},   author = {Nick Isaac and Tom August and Dylan Carbone and Colin Harrower and Jack Hatfield and Mark Hill and Francesca Mancini and Charlie Outhwaite and Gary Powney},   year = {2024},   note = {R package version 0.2.19},   url = {https://github.com/BiologicalRecordsCentre/sparta}, }"},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Trend Analysis for Unstructured Data","text":"install development version sparta, ’s easiest use devtools package: difficulties installing sparta using method try updating version R --date version available. still problems please contact us use issues page.","code":"# install.packages(\"devtools\") # NOTE: If you have not installed devtools before you will need to restart you R # session before installing to avoid problems  library(devtools)  # Some users have reported issues with devtools not correctly installing # dependencies. Run the following lines to avoid these issues list.of.packages <- c(\"minqa\", \"lme4\", \"gtools\", \"gtable\", \"scales\",                       \"assertthat\", \"magrittr\", \"tibble\", \"stringr\") new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])] if(length(new.packages)) install.packages(new.packages)  # Now install sparta install_github('BiologicalRecordsCentre/sparta')  # Load sparta library(sparta)"},{"path":"/index.html","id":"vignettetutorial","dir":"","previous_headings":"","what":"Vignette/Tutorial","title":"Trend Analysis for Unstructured Data","text":"written vignette support package can view PLEASE NOTE SINCE PACKAGE DEVELOPMENT STRUCTURE FUNCTIONALITY PACKAGE LIKELY CHANGE TIME. TRY KEEP TUTORIALS DATE WORKS CURRENT MASTER VERSION GITHUB","code":""},{"path":"/reference/createWeights.html","id":null,"dir":"Reference","previous_headings":"","what":"Create frescalo weights file — createWeights","title":"Create frescalo weights file — createWeights","text":"Create weights file required run frescalo, outlined (Hill, 2011). information frescalo see frescalo. function takes table geographical distances sites table numeric data calculate similarity (example, landcover abiotic data)","code":""},{"path":"/reference/createWeights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create frescalo weights file — createWeights","text":"","code":"createWeights(   distances,   attributes,   dist_sub = 200,   sim_sub = 100,   normalise = FALSE,   verbose = TRUE )"},{"path":"/reference/createWeights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create frescalo weights file — createWeights","text":"distances dataframe giving distance sites long format three columns. first column give ID first site, second column gives ID second site third column gives distance . table include reciprocal data .e. rows ', B, 10' 'B, , 10' exist. attributes dataframe numeric attributes site. first column must contain site IDs columns used calculate similarity sites using dist() method 'euclidean'. dist_sub number neighbours include ranking distance. Hill (2011), set 200 default sim_sub number neighbours include ranking similarity. final number sites included neighbourhood. Hill (2011), set 100 default . normalise Logical. TRUE attribute divided maximum value  produce values 0 1. Default FALSE verbose Logical, progress printed console. Defaults TRUE","code":""},{"path":"/reference/createWeights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create frescalo weights file — createWeights","text":"dataframe returned format can used directly frescalo()          sparta(). dataframe three columns giving target cell, neighbourhood         cell, weight.","code":""},{"path":"/reference/createWeights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create frescalo weights file — createWeights","text":"Hill, Mark. Local frequency key interpreting species occurrence data recording effort known. 2011. Methods Ecology Evolution, 3 (1), 195-205.","code":""},{"path":"/reference/createWeights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create frescalo weights file — createWeights","text":"","code":"if (FALSE) {  mySites <- paste('Site_', 1:100, sep = '')  # Build a table of distances myDistances <- merge(mySites, mySites)   # add random distances myDistances$dist <- runif(n = nrow(myDistances), min = 10, max = 10000)   # to be realistic the distance from a site to itself should be 0 myDistances$dist[myDistances$x == myDistances$y] <- 0  # Build a table of attributes myHabitatData <- data.frame(site = mySites,                             grassland = runif(length(mySites), 0, 1),                             woodland = runif(length(mySites), 0, 1),                             heathland = runif(length(mySites), 0, 1),                             urban = runif(length(mySites), 0, 1),                             freshwater = runif(length(mySites), 0, 1))  # This pretend data is supposed to be proportional cover so lets  # make sure each row sums to 1 multiples <- apply(myHabitatData[,2:6], 1, sum) for(i in 1:length(mySites)){   myHabitatData[i,2:6] <- myHabitatData[i,2:6]/multiples[i] }  # Create the weights file weights <- createWeights(distances = myDistances,                           attributes = myHabitatData,                           dist_sub = 20,                           sim_sub = 10) }"},{"path":"/reference/dataDiagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Diagnostics — dataDiagnostics","title":"Data Diagnostics — dataDiagnostics","text":"function provides visualisations number records dataset changes time number species recorded visit changes time. linear model run test significant trend.","code":""},{"path":"/reference/dataDiagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data Diagnostics — dataDiagnostics","text":"","code":"dataDiagnostics(taxa, site, time_period, plot = TRUE, progress_bar = TRUE)"},{"path":"/reference/dataDiagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data Diagnostics — dataDiagnostics","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. time_period numeric vector user defined time periods, date vector, long number observations. plot Logical, TRUE plots model results printed console progress_bar TRUE progress bar printed console","code":""},{"path":"/reference/dataDiagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data Diagnostics — dataDiagnostics","text":"list filepaths, one species run, giving location         output saved .rdata file, containing object called ''","code":""},{"path":"/reference/dataDiagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data Diagnostics — dataDiagnostics","text":"","code":"if (FALSE) {  ### Diagnostics functions ### # Create data n <- 2000 # size of dataset nyr <- 20 # number of years in data nSamples <- 200 # set number of dates useDates <- TRUE  # Create somes dates first <- as.POSIXct(strptime(\"2003/01/01\", \"%Y/%m/%d\")) last <- as.POSIXct(strptime(paste(2003+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\")) dt <- last-first rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(c('one', 'two', 'three'), size = n, TRUE)  # the date of visit is selected at random from those created earlier if(useDates){   time_period <- sample(rDates, size = n, TRUE) } else {   time_period <- sample(1:nSamples, size = n, TRUE) } # Using a date dataDiagnostics(taxa, site, time_period) # Using a numeric dataDiagnostics(taxa, site, as.numeric(format(time_period, '%Y'))) }"},{"path":"/reference/dataMetrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate dataset metrics — dataMetrics","title":"Calculate dataset metrics — dataMetrics","text":"Takes formattedOccData object name species. Runs set calculations dataset species Based rules thumb. Original version Mark Logie; integrated sparta NJBI","code":""},{"path":"/reference/dataMetrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate dataset metrics — dataMetrics","text":"","code":"dataMetrics(sp, formattedData, verbose = FALSE)"},{"path":"/reference/dataMetrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate dataset metrics — dataMetrics","text":"sp character string identifying species name formattedData output formattedOccData verbose Logical. Default (`FALSE`) returns seven metrics.","code":""},{"path":"/reference/dataMetrics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate dataset metrics — dataMetrics","text":"Pocock, Logie, Isaac, Outhwaite & August (2019).  Rapid assessment suitability multi-species citizen  science datasets occupancy trend analysis. bioRxiv 813626 doi:10.1101/813626.","code":""},{"path":"/reference/date2timeperiod.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign dates to time periods — date2timeperiod","title":"Assign dates to time periods — date2timeperiod","text":"function assigns dates timeperiods nessecary step methods use time periods  rather dates, Frescalo Telfer","code":""},{"path":"/reference/date2timeperiod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign dates to time periods — date2timeperiod","text":"","code":"date2timeperiod(Date, time_periods)"},{"path":"/reference/date2timeperiod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign dates to time periods — date2timeperiod","text":"Date Either vector dates 2 column data.frame first column start date second column end date. time_periods data.frame two columns, first column gives start year time period second column gives end year. year ranges inclusive.","code":""},{"path":"/reference/date2timeperiod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign dates to time periods — date2timeperiod","text":"vector, length date giving time periods. Time period 1 time period earliest start year, 2 second earliest start year . dates fit time period overlap time period given NA value","code":""},{"path":"/reference/date2timeperiod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign dates to time periods — date2timeperiod","text":"","code":"# Create data n <- 15000 #size of dataset nyr <- 20 # number of years in data nSamples <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"1980/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(1980+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  Date <- first + (runif(nSamples)*dt)  # Create time periods dataframe time_periods <- data.frame(start=c(1980,1990),end=c(1989,1999))  # Create time periods column using a vector tps <- date2timeperiod(Date = Date, time_periods = time_periods)   # Create time periods column using a data.frame tps <- date2timeperiod(Date = data.frame(start = Date, end = (Date+100)),                        time_periods = time_periods)"},{"path":"/reference/formatOccData.html","id":null,"dir":"Reference","previous_headings":"","what":"Format data for Occupancy detection models — formatOccData","title":"Format data for Occupancy detection models — formatOccData","text":"takes occurrene data form vector taxa names, locations survey (usually date) converts form needed occupancy models (see value section)","code":""},{"path":"/reference/formatOccData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format data for Occupancy detection models — formatOccData","text":"","code":"formatOccData(   taxa,   site,   survey,   replicate = NULL,   closure_period = NULL,   includeJDay = FALSE )"},{"path":"/reference/formatOccData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format data for Occupancy detection models — formatOccData","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. survey vector long number observations.  must Date either closure_period supplied includeJDay = TRUE replicate optional vector identify replicate samples (visits) per survey. Need globally unique (e.g can 1, 2, .. n within surveys) closure_period optional vector integers specifying closure period.  FALSE closure_period extracted year survey. includeJDay Logical. TRUE Julian day column returned occDetData object.","code":""},{"path":"/reference/formatOccData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format data for Occupancy detection models — formatOccData","text":"list length 2 first element 'spp_vis' data.frame visit  (unique combination site time period) first column taxa  following columns. Values taxa columns either TRUE  FALSE depending whether observed visit. second  element ('occDetData') dataframe giving site, list length (number  species observed visit) year (time period) visit. Optionally also includes  Julian Day column, centered 1 July.","code":""},{"path":"/reference/formatOccData.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Format data for Occupancy detection models — formatOccData","text":"Isaac, N.J.B., van Strien, .J., August, T.., de Zeeuw, M.P. Roy, D.B. (2014).             Statistics citizen science: extracting signals change noisy ecological data.             Methods Ecology Evolution, 5 (10), 1052-1060. van Strien, .J., Termaat, T., Groenendijk, D., Mensing, V. & Kéry, M. (2010).             Site-occupancy models may offer new opportunities dragonfly monitoring based daily species lists.             Basic Applied Ecology, 11, 495-503.","code":""},{"path":"/reference/formatOccData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format data for Occupancy detection models — formatOccData","text":"","code":"if (FALSE) {  # Create data n <- 15000 #size of dataset nyear <- 20 # number of years in data nSurveys <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"2010/01/01\", format=\"%Y/%m/%d\"))  last <- as.Date(strptime(paste(2010+(nyear-1),\"/12/31\", sep=''), format=\"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSurveys)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(rDates, size = n, TRUE)  # run the model with these data for one species formatted_data <- formatOccData(taxa = taxa,                                 site = site,                                 survey = survey,                                 includeJDay = TRUE) } if (FALSE) {  # Create data with coarser survey information n <- 1500 #number of species observation in dataset np <- 10 # number of closure periods in data nSurveys <- 100 # set number of surveys nSites <- 20 # set number of sites  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(nSurveys, size = n, TRUE)  # allocate the surveys randomly to closure periods  cp <- sample(1:np, nSurveys, TRUE) closure_period <- cp[survey]  # run the model with these data for one species formatted_data <- formatOccData(taxa = taxa,                                 site = site,                                 survey = survey,                                 closure_period = closure_period)   # OR format the unicorns data formatted_data <- formatOccData(taxa = unicorns$species,                                survey = unicorns$start_date,                                site = unicorns$site)  }"},{"path":"/reference/frescalo.html","id":null,"dir":"Reference","previous_headings":"","what":"Frescalo trend analysis — frescalo","title":"Frescalo trend analysis — frescalo","text":"function using Frescalo (Hill, 2011), tool analysing occurrence data recording effort known. function returns output Frescalo  R session saves path specified sinkdir. setting  plot_fres TRUE maps results also saved. Plotting  returned object gives useful summary.","code":""},{"path":"/reference/frescalo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frescalo trend analysis — frescalo","text":"","code":"frescalo(   Data,   frespath,   time_periods,   site_col,   sp_col,   year_col = NULL,   start_col = NULL,   end_col = NULL,   species_to_include = NULL,   sinkdir = NULL,   plot_fres = FALSE,   Fres_weights = \"LCGB\",   non_benchmark_sp = NULL,   fres_site_filter = NULL,   phi = 0.74,   alpha = 0.27,   trend_option = \"arithmetic\",   NYears = 10,   ignore.ireland = F,   ignore.channelislands = F )"},{"path":"/reference/frescalo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frescalo trend analysis — frescalo","text":"Data dataframe object. consist rows observations columns indicating species location well either year observation columns specifying start end dates observation. important date columns date format. frespath path frescalo .exe file. can downloaded http://www.brc.ac.uk/biblio/frescalo-computer-program-analyse--biological-records. currently available Windows. directory .exe saved writeable. time_periods dataframe object two columns. first column contains start year time period second column contains end year  time period. Time periods overlap. site_col name site column Data sp_col name species column Data year_col name year column Data start_col name start date column Data end_col name end date column Data species_to_include Optionally character vector listing names species used. Species list ignored. useful interested subset species. sinkdir String giving output directory results plot_fres Logical, TRUE maps produced Frescalo. Default  FALSE. CURRENTLY WORKS UK GRID-REFERENCE DATA Fres_weights 'LC*' specifies weights files based landcover data. suffix specifies extend ('LCUK', 'LCNI' 'LCGB'). 'VP' uses weights file based vascular plant data UK , included package. Alternativly custom weights file can given data.frame. must three columns: target cell, neighbour cell, weight. Default 'LCGB' non_benchmark_sp character vector, giving names species used benchmarks Frescalo. Default NULL species used. See Hill, 2011 reasons species may suitable benchmarks. fres_site_filter Optionally character vector giving names sites used trend analysis. Sites include list used estimating TFactors. Default NULL sites used. phi Target frequency frequency-weighted mean frequency. Default 0.74 Hill (2011). set NULL, phi start 0.74 increased value smaller 98.5 percentile input phi, limited maximum 0.95. alpha proportion expected number species cell treated benchmarks. Default 0.27 Hill (2011). limited 0.08 0.50. trend_option Set method wish calculate percentage change. can currently set either 'arithmetic' (default) 'geometric'. Arimthmetic calculates percentage change linear fashion decline 50% 50 years equal 10% 10 years. Using example Geometric trend 8.44% every 10 years work compound rate. NYears number years want percentage change calculated (.e. 10 gives decadal change). Default = 10 ignore.ireland Logical, TRUE Irish hectads removed. Default FALSE ignore.channelislands Logical, TRUE channel island hectads  removed. Default FALSE","code":""},{"path":"/reference/frescalo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frescalo trend analysis — frescalo","text":"Results saved file returned list R. list object returned comprised following: $paths list file paths provides locations raw data files         $log, $stat, $freq $trend, order $trend dataframe provides list time factors species $stat Location report $freq Listing rescaled species frequencies $log records output sent console running frescalo $lm_stats results linear modelling TFactors  following columns produced two time periods","code":""},{"path":"/reference/frescalo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Frescalo trend analysis — frescalo","text":"Hill, Mark. Local frequency key interpreting species occurrence data recording effort known. 2011. Methods Ecology Evolution, 3 (1), 195-205.","code":""},{"path":"/reference/frescalo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frescalo trend analysis — frescalo","text":"","code":"if (FALSE) { # Load data data(unicorns)  fres_out <- frescalo(Data = unicorns,                      frespath = file.path(getwd(), \"frescalo.exe\"),                      time_periods = data.frame(start=c(1980,1990),end=c(1989,1999)),                      site_col = 'site',                      sp_col = 'species',                      start_col = 'start_date',                      end_col = 'end_date') }"},{"path":"/reference/getBugsData.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the bugs data object depending on the type of model you are running — getBugsData","title":"Modify the bugs data object depending on the type of model you are running — getBugsData","text":"function primarily internal use within occDetFunc. used  update bugs data according needs model type.","code":""},{"path":"/reference/getBugsData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the bugs data object depending on the type of model you are running — getBugsData","text":"","code":"getBugsData(bugs_data, modeltype, verbose = FALSE, occDetData)"},{"path":"/reference/getBugsData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the bugs data object depending on the type of model you are running — getBugsData","text":"bugs_data bugs data object. list specified occDetFunc  list(y = .numeric(focal), Year = TP, Site = rownum, nyear = nTP, nsite = nrow(zst), nvisit = nrow(occDetdata[,])). focal binary (0/1) focal species present, Year time periods survey periods, Site site identifiers, nyear number years data, nsite hte number sites nVisit number visits modeltype Character, one : intercept, centering, jul_date, catlistlength, contlistlength. See occDetFunc information. verbose Logical, true progress reported console occDetData 'raw' data used create bugs_data.  column 'L' list length column 'JulDate' Julian date","code":""},{"path":"/reference/getBugsData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the bugs data object depending on the type of model you are running — getBugsData","text":"updated bugs_data object","code":""},{"path":"/reference/getInitValues.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the init object depending on the type of model we are running — getInitValues","title":"Modify the init object depending on the type of model we are running — getInitValues","text":"function primarily internal use within occDetFunc. used  update initial values object according needs model type.","code":""},{"path":"/reference/getInitValues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the init object depending on the type of model we are running — getInitValues","text":"","code":"getInitValues(init, modeltype, verbose = FALSE)"},{"path":"/reference/getInitValues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the init object depending on the type of model we are running — getInitValues","text":"init initial values object. minimum list defined occDetFunc list(z = z, alpha.p = rep(runif(1, -2, 2), nTP), = rep(runif(1, -2, 2), nTP), eta = rep(runif(1, -2, 2), bugs_data$nsite)). z 1's/0's whether focal species present, alpha.p initial values detectability year,  inital values occupancy probability year, eta initial values site random effects. modeltype Character, one : intercept, centering, contlistlength. See occDetFunc information. verbose Logical, true progress reported console","code":""},{"path":"/reference/getInitValues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the init object depending on the type of model we are running — getInitValues","text":"updated init (initial values) object","code":""},{"path":"/reference/getModelFile.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a sparta JAGS model file fitting your needs — getModelFile","title":"Create a sparta JAGS model file fitting your needs — getModelFile","text":"function primarily internal use within occDetFunc. used  write model file fits users needs, path file returned.","code":""},{"path":"/reference/getModelFile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a sparta JAGS model file fitting your needs — getModelFile","text":"","code":"getModelFile(   modeltype,   regional_codes = NULL,   region_aggs = NULL,   verbose = FALSE )"},{"path":"/reference/getModelFile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a sparta JAGS model file fitting your needs — getModelFile","text":"modeltype Character, see occDetFunc information. regional_codes data.frame object detailing site associated region. row desginates site column represents region. first column represents  site name (site). Subsequent columns named regions 1 representing site region 0 . NOTE site one region region_aggs named list giving aggregations regions want trend estimates . example region_aggs = list(GB = c('england', 'scotland', 'wales')) produced trend GB (Great Britain) well constituent nations. Note 'england', scotland' 'wales' must appear names columns regional_codes.  one aggregate can given, eg region_aggs = list(GB = c('england', 'scotland', 'wales'), UK = c('england', 'scotland', 'wales', 'northern_ireland')). verbose Logical, true progress reported console","code":""},{"path":"/reference/getModelFile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a sparta JAGS model file fitting your needs — getModelFile","text":"path model file.","code":""},{"path":"/reference/getObsModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the observation model component of a sparta JAGS model — getObsModel","title":"Create the observation model component of a sparta JAGS model — getObsModel","text":"function primarily internal use within getModelFile. used  write observation model fits users needs. model returned character.","code":""},{"path":"/reference/getObsModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the observation model component of a sparta JAGS model — getObsModel","text":"","code":"getObsModel(modeltype, verbose = FALSE)"},{"path":"/reference/getObsModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the observation model component of a sparta JAGS model — getObsModel","text":"modeltype Character, one : jul_date, catlistlength, contlistlength. See occDetFunc information. verbose Logical, true progress reported console","code":""},{"path":"/reference/getObsModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the observation model component of a sparta JAGS model — getObsModel","text":"character, JAGS model code, describes observation model.","code":""},{"path":"/reference/getParameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify the initial values object depending on the type of model we are running — getParameters","title":"Modify the initial values object depending on the type of model we are running — getParameters","text":"function primarily internal use within occDetFunc. used  return vector parameters monitored.","code":""},{"path":"/reference/getParameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify the initial values object depending on the type of model we are running — getParameters","text":"","code":"getParameters(parameters, modeltype, verbose = FALSE)"},{"path":"/reference/getParameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify the initial values object depending on the type of model we are running — getParameters","text":"parameters character vector parameters want monitor. modeltype Character, one : indran, jul_date, catlistlength, contlistlength. See occDetFunc information. verbose Logical, true progress reported console","code":""},{"path":"/reference/getParameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modify the initial values object depending on the type of model we are running — getParameters","text":"character, JAGS model code, describes observation model.","code":""},{"path":"/reference/gps_latlon2gr.html","id":null,"dir":"Reference","previous_headings":"","what":"Covert latitude and longitude to other formats — gps_latlon2gr","title":"Covert latitude and longitude to other formats — gps_latlon2gr","text":"Coverts latitude longitude grid reference /easting northing.","code":""},{"path":"/reference/gps_latlon2gr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Covert latitude and longitude to other formats — gps_latlon2gr","text":"","code":"gps_latlon2gr(   latitude,   longitude,   out_projection = \"OSGB\",   return_type = \"both\" )"},{"path":"/reference/gps_latlon2gr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Covert latitude and longitude to other formats — gps_latlon2gr","text":"latitude vector numerics giving latitudes longitude vector numerics giving longitudes out_projection string giving desired output projection, either \"OSGB\" \"OSNI\". Defaults \"OSGB\". return_type string defining information funtion return. \"\" (default), grid reference easting/northing returned.  \"en\", easting northing returned. gr, grid reference returned","code":""},{"path":"/reference/gps_latlon2gr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Covert latitude and longitude to other formats — gps_latlon2gr","text":"dataframe results returned","code":""},{"path":"/reference/gps_latlon2gr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Covert latitude and longitude to other formats — gps_latlon2gr","text":"","code":"gps_latlon2gr(51.60233, -1.111254) #>        GRIDREF EASTING NORTHING #> 1 SU6164989650  461649   189650"},{"path":"/reference/gr2gps_latlon.html","id":null,"dir":"Reference","previous_headings":"","what":"Covert grid reference to latitude and longitude — gr2gps_latlon","title":"Covert grid reference to latitude and longitude — gr2gps_latlon","text":"Covert grid reference latitude longitude","code":""},{"path":"/reference/gr2gps_latlon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Covert grid reference to latitude and longitude — gr2gps_latlon","text":"","code":"gr2gps_latlon(gridref, precision = NULL, projection = \"OSGB\", centre = TRUE)"},{"path":"/reference/gr2gps_latlon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Covert grid reference to latitude and longitude — gr2gps_latlon","text":"gridref vector strings giving grid references changed precision gives precision grid references. Must length gridref. precision given meters numeric .e. 10km square = 10000, 1km square = 1000. NULL function tries work precision . projection specifies projection input can either \"OSGB\"  \"OSNI\". Defaults \"OSGB\" centre TRUE coordinates centre cell given else FALSE coordinates bottom left corner given.","code":""},{"path":"/reference/gr2gps_latlon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Covert grid reference to latitude and longitude — gr2gps_latlon","text":"dataframe results returned","code":""},{"path":"/reference/gr2gps_latlon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Covert grid reference to latitude and longitude — gr2gps_latlon","text":"","code":"gr2gps_latlon('SU616896') #>   LATITUDE LONGITUDE #> 1 51.60233 -1.111254"},{"path":"/reference/gridref_regions.html","id":null,"dir":"Reference","previous_headings":"","what":"A dataset of UK grid references with regions — gridref_regions","title":"A dataset of UK grid references with regions — gridref_regions","text":"dataset 1km-square UK grid references regions ENGLAND, WALES, SCOTLAND, NORTHERN_IRELAND","code":""},{"path":"/reference/gridref_regions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A dataset of UK grid references with regions — gridref_regions","text":"","code":"gridref_regions"},{"path":"/reference/gridref_regions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A dataset of UK grid references with regions — gridref_regions","text":"Rob Cooke, 2021-02-15","code":""},{"path":"/reference/htmlSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create HTML Report — htmlSummary","title":"Create HTML Report — htmlSummary","text":"Create HTML Report occDet object.","code":""},{"path":"/reference/htmlSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create HTML Report — htmlSummary","text":"","code":"htmlSummary(occDet, open = TRUE, output_dir = getwd(), output_file = NULL, ...)"},{"path":"/reference/htmlSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create HTML Report — htmlSummary","text":"occDet object class occDet open Logical, TRUE html report opened complete output_dir Character, directory html file saved, defaults working directory. output_file (Optional) file name given html file ... Additional arguments passed rmarkdown::render","code":""},{"path":"/reference/htmlSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create HTML Report — htmlSummary","text":"Path html report","code":""},{"path":[]},{"path":"/reference/occDetFunc.html","id":null,"dir":"Reference","previous_headings":"","what":"Occupancy detection Function — occDetFunc","title":"Occupancy detection Function — occDetFunc","text":"Run occupancy detection models using output formatOccData","code":""},{"path":"/reference/occDetFunc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Occupancy detection Function — occDetFunc","text":"","code":"occDetFunc(   taxa_name,   occDetdata,   spp_vis,   n_iterations = 5000,   nyr = 2,   burnin = 1500,   thinning = 3,   n_chains = 3,   write_results = TRUE,   output_dir = getwd(),   modeltype = \"sparta\",   max_year = NULL,   seed = NULL,   model.function = NULL,   regional_codes = NULL,   region_aggs = NULL,   additional.parameters = NULL,   additional.BUGS.elements = NULL,   additional.init.values = NULL,   return_data = FALSE,   criterion = 1,   provenance = NULL,   saveMatrix = FALSE,   rem_aggs_with_missing_regions = FALSE,   allowSitesMultiRegions = FALSE )"},{"path":"/reference/occDetFunc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Occupancy detection Function — occDetFunc","text":"taxa_name character giving name species modelled. occDetdata 2nd element object returned formatOccData. spp_vis 1st element object returned formatOccData. n_iterations numeric, MCMC parameter - number interations nyr numeric, minimum number periods site must records included models. Defaults 2 burnin numeric, MCMC parameter - length burn thinning numeric, MCMC parameter - thinning factor n_chains numeric, MCMC parameter - number chains run write_results logical, results saved output_dir. recommended since models can take long time run. TRUE (default) results species saved .rdata file species run. prevents loss data anything go wrong. output_dir character, output directory output taxa saved .rdata files. defualt working directory modeltype character string vector strings specifies model use. See details. used model.function ignored. max_year numeric, final year analysis run, can set beyond limit dataset.  Defaults final year dataset. seed numeric, uses set.seed set randon number seed. Setting number ensures repeatabl analyses model.function optionally user defined BUGS model coded function (see ?jags, including example , done) regional_codes data.frame object detailing site associated region. row desginates site column represents region. first column represents site name (site). Subsequent columns named regions 1 representing site region 0 . NOTE site one region region_aggs named list giving aggregations regions want trend estimates . example region_aggs = list(GB = c('england', 'scotland', 'wales')) produced trend GB (Great Britain) well constituent nations. Note 'england', scotland' 'wales' must appear names columns regional_codes. one aggregate can given, eg region_aggs = list(GB = c('england', 'scotland',  'wales'), UK = c('england', 'scotland', 'wales', 'northern_ireland')). additional.parameters character vector additional parameters monitor additional.BUGS.elements named list giving additioanl bugs elements passed R2jags::jags 'data' argument additional.init.values named list giving user specified initial values added defaults. return_data Logical, TRUE (default) BUGS data object returned data criterion Determines whether model run. integer defines threshold number records (50 Outhwaite et al 2019). options `EqualWt` `HighSpec`, define application \"rules thumb\" defined Pocock et al 2019. Defaults 1, case model applied long single record focal species. provenance optional text string allowing user identify dataset. saveMatrix Logical, FALSE (default) sims.matrix element jags object omitted, order reduce filesize. rem_aggs_with_missing_regions option TRUE remove aggregates contain least one region data. `FALSE`, aggregates regions aggregate contain data, dropped. Defaults FALSE allowSitesMultiRegions option permits sites included one region `TRUE`. `FALSE` sites dropped. Defaults `FALSE`","code":""},{"path":"/reference/occDetFunc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Occupancy detection Function — occDetFunc","text":"list including model, JAGS model output, path model file used information number iterations, first year, last year, etc. Key aspects model output include: \"$model\" - model used provided JAGS. Also contained list fully observed variables. listed BUGS data. \"$BUGSoutput$n.chains\" - number Markov chains ran MCMC simulations. \"$BUGSoutput$n.iter\" - total number iterations per chain. \"$BUGSoutput$n.burnin\" - number interations discarded start burn-period. \"$BUGSoutput$n.thin\" - thinning rate used. example thinning rate 3 retains every third iteration. used reduce autocorrelation. \"$BUGSoutput$n.keep\" - number iterations kept per chain. total number iterations minus burn-divided thinning rate. \"$BUGSoutput$n.sims\" - total number iterations kept. \"$BUGSoutput$summary\" - summary table monitored parameter. posterior distribution parameter summaried mean, standard deviation, various credible intervals, formal convergence metric (Rhat), measure effective sample size (n.eff). \"$BUGSoutput$mean\" - mean values monitored parameters \"$BUGSoutput$sd\" - standard deviation values monitored parameters \"$BUGSoutput$median\" - median values monitored parameters \"$parameters..save\" - names monitored parameters. \"$BUGSoutput$model.file\" - user provided temporary generated model file detailing occupancy model. \"$n.iter\" - total number interations per chain. \"$DIC\" - Whether Deviance Information Criterion (DIC) calculated. \"$BUGSoutput$sims.list\" - list posterior distribution monitored parameter. Use sims.array sims.matrix different format posteriors desired. \"$SPP_NAME\" - name study species. \"$min_year\" - First year data included occupancy model run. \"$max_year\" - Final year data included occupancy model run final year specified user. \"$sites_included\" - List sites taken forward model (filtering) \"$nsites\" - number unique sites included occupancy model run. \"$nvisits\" - number unique visits included int occupancy model run. \"$species_observations\" - number unique records species interest. \"$sparta_version\" - version sparta used run model. \"$regions\" - names regions included model run. \"$region_aggs\" - names region aggregates included model run. See also `metadata` attribute detailed information data model.","code":""},{"path":"/reference/occDetFunc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Occupancy detection Function — occDetFunc","text":"function requires program JAGS. installed default sparta loaded installed user. details can found vignette. modeltype used choose model well associated initial values, parameters monitor. Elements choose can separated following components: . Prior type: 3 options, tested Outhwaite et al (review):   1. sparta - uses model Isaac et al (2014).   2. indran - adaptive stationary model.   3. ranwalk - random walk model. B. Hyperprior type: 3 options, discussed Outhwaite et al (review):   1. halfuniform - original formulation Isaac et al (2014).   2. halfcauchy - preferred form, tested Outhwaite et al (2018).   3. inversegamma - alternative form presented literature. C. List length specification:  3 options:   1. catlistlength - list length categorical variable.   2. contlistlength - list length continuous variable.   3. nolistlength - list length variable. D. Julian date: additional option including Julian date within detection model:   1. jul_date. combinations available sparta. get error try use combination supported. usually good reason combination good idea. model elements available: \"sparta\" - uses model Isaac et al (2014) \"indran\" - prior year effect state model modelled random effect.  allows model adapt interannual variability. \"ranwalk\" - prior year effect state model modelled random walk.  estimate year effect dependent previous year. \"halfcauchy\" - Includes half-Cauchy hyperpriors random effects within model.  half-Cauchy special case Student’s t distribution 1 degree freedom. \"inversegamma\" - Includes inverse-gamma hyperpriors random effects within model \"catlistlength\" - specifies list length considered catagorical variable. 3 classes, lists length 1, 2-3, 4 . none list length options specifed 'contlistlength' used \"contlistlength\" - specifies list length considered continious variable. none list length options specifed 'contlistlength' used \"nolistlength\" - specifies list length used. none list length options specifed 'contlistlength' used \"jul_date\" - adds Julian date model normal distribution mean standard deviation monitered parameters. \"intercept\" - longer available. Includes intercept term state observation model.  including intercept terms, occupancy detection probabilities year centred overall mean level. \"centering\" - longer available. Includes hierarchical centering model parameters.   Centring change model explicitly writes way allows parameter estimates updated simultaneously. options provided vector characters, e.g. modeltype = c('indran', 'halfcauchy', 'catlistlength')","code":""},{"path":"/reference/occDetFunc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Occupancy detection Function — occDetFunc","text":"Isaac, N.J.B., van Strien, .J., August, T.., de Zeeuw, M.P. Roy, D.B. (2014).             Statistics citizen science: extracting signals change noisy ecological data.             Methods Ecology Evolution, 5: 1052-1060. Outhwaite, C.L., Chandler, R.E., Powney, G.D., Collen, B., Gregory, R.D. & Isaac, N.J.B. (2018).             Prior specification Bayesian occupancy modelling improves analysis species occurrence data.             Ecological Indicators, 93: 333-343. Pocock, Logie, Isaac, Outhwaite & August. Rapid assessment suitability multi-species citizen science datasets occupancy trend analysis. bioRxiv 813626 (2019) doi:10.1101/813626.","code":""},{"path":"/reference/occDetFunc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Occupancy detection Function — occDetFunc","text":"","code":"if (FALSE) {  set.seed(123)  # Create data n <- 15000 # size of dataset nyear <- 20 # number of years in data nSamples <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"2010/01/01\", format = \"%Y/%m/%d\")) last <- as.Date(strptime(paste(2010 + (nyear - 1), \"/12/31\", sep = \"\"), format = \"%Y/%m/%d\")) dt <- last - first rDates <- first + (runif(nSamples) * dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # sites are visited randomly site <- sample(paste(\"A\", 1:nSites, sep = \"\"), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(rDates, size = n, TRUE)  # Format the data visitData <- formatOccData(taxa = taxa, site = site, survey = survey)  # run the model with these data for one species (very small number of iterations) results <- occDetFunc(   taxa_name = taxa[1],   n_iterations = 50,   burnin = 15,   occDetdata = visitData$occDetdata,   spp_vis = visitData$spp_vis,   write_results = FALSE,   provenance = \"sparta test dataset\" ) }"},{"path":"/reference/occDetModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Occupancy detection models — occDetModel","title":"Occupancy detection models — occDetModel","text":"Run occupancy detection models described Isaac et al, 2014","code":""},{"path":"/reference/occDetModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Occupancy detection models — occDetModel","text":"","code":"occDetModel(   taxa,   site,   survey,   replicate = NULL,   closure_period = NULL,   criterion = 1,   provenance = NULL,   rem_aggs_with_missing_regions = TRUE,   allowSitesMultiRegions = FALSE,   species_list = unique(taxa),   write_results = TRUE,   output_dir = getwd(),   nyr = 2,   n_iterations = 5000,   burnin = 1500,   thinning = 3,   n_chains = 3,   modeltype = \"sparta\",   regional_codes = NULL,   region_aggs = NULL,   model.function = NULL,   max_year = NULL,   seed = NULL,   additional.parameters = NULL,   additional.BUGS.elements = NULL,   additional.init.values = NULL,   return_data = FALSE )"},{"path":"/reference/occDetModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Occupancy detection models — occDetModel","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. survey  vector long number observations.  must Date includeJDay = TRUE replicate optional vector identify replicate samples (visits) per survey. Need globally unique (e.g can 1, 2, .. n within surveys) closure_period optional vector integers specifying closure period.  FALSE closure_period extracted year survey. criterion Determines whether model run. integer defines threshold number records (50 Outhwaite et al 2019). options `EqualWt` `HighSpec`, define application \"rules thumb\" defined Pocock et al 2019.  Defaults 1, case model applied long single record focal species. provenance optional text string allowing user identify dataset. rem_aggs_with_missing_regions option TRUE remove aggregates contain least one region data. allowSitesMultiRegions option permits sites included one region. `FALSE` sites dropped. species_list character vector taxa names models run. optional default models run taxa write_results logical, results saved output_dir. recommended since models can take long time run. TRUE (default) results species saved .rdata file species run. prevents loss data anything go wrong. output_dir character, output directory output taxa saved .rdata files. defualt working directory nyr numeric, minimum number years site must records included models n_iterations numeric, MCMC parameter - number interations burnin numeric, MCMC parameter - length burn thinning numeric, MCMC parameter - thinning factor n_chains numeric, MCMC parameter - number chains run modeltype character string vector specifies model use. See details. used model.function ignored. regional_codes data.frame object detailing site associated region. row desginates site column represents region. first column represents  site name (site). Subsequent columns named regions 1 representing site region 0 . NOTE site one region region_aggs named list giving aggregations regions want trend estimates . example region_aggs = list(GB = c('england', 'scotland', 'wales')) produced trend GB (Great Britain) well constituent nations. Note 'england', scotland' 'wales' must appear names columns regional_codes.  one aggregate can given, eg region_aggs = list(GB = c('england', 'scotland',  'wales'), UK = c('england', 'scotland', 'wales', 'northern_ireland')). model.function optionally user defined BUGS model coded function (see ?jags, including example , done) max_year numeric, final year analysis run, can set beyond limit dataset.  Defaults final year dataset. seed numeric, uses set.seed set randon number seed. Setting number ensures repeatabl analyses additional.parameters character vector additional parameters monitor additional.BUGS.elements named list giving additioanl bugs elements passed  R2jags::jags 'data' argument additional.init.values named list giving user specified initial values  added defaults. return_data Logical, TRUE (default) bugs data object returned data","code":""},{"path":"/reference/occDetModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Occupancy detection models — occDetModel","text":"list occDet objects (see occDetFunc), occDetList class object","code":""},{"path":"/reference/occDetModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Occupancy detection models — occDetModel","text":"function requires R package R2jags program JAGS. installed default sparta loaded installed user. details can found vignette. modeltype used choose model well associated initial values, parameters monitor. Elements choose can separated following components: . Prior type: 3 options, tested Outhwaite et al (review):   1. sparta - uses model Isaac et al (2014).   2. indran - adaptive stationary model.   3. ranwalk - random walk model. B. Hyperprior type: 3 options, discussed Outhwaite et al (review):   1. halfuniform - original formulation Isaac et al (2014).   2. halfcauchy - preferred form, tested Outhwaite et al (review).   3. inversegamma - alternative form presented literature. C. List length specification:  3 options:   1. catlistlength - list length categorical variable.   2. contlistlength - list length continuous variable.   3. nolistlength - list length variable. D. Julian date: additional option including Julian date within detection model:   1. jul_date. combinations available sparta. get error try use combination supported. usually good reason combination good idea. model elements available: \"sparta\" - uses model Isaac et al (2014). \"indran\" - prior year effect state model modelled random effect. allows model adapt interannual variability. \"ranwalk\" - prior year effect state model modelled random walk. estimate year effect dependent previous year. \"halfcauchy\" - Includes half-Cauchy hyperpriors random effects within model. half-Cauchy special case Student’s t distribution 1 degree freedom. \"inversegamma\" - Includes inverse-gamma hyperpriors random effects within model. \"catlistlength\" - specifies list length considered categorical variable. 3 classes: lists length 1, 2-3, 4 . none list length options specified, 'contlistlength' used. \"contlistlength\" - specifies list length considered continuous variable. none list length options specified, 'contlistlength' used. \"nolistlength\" - specifies list length used. none list length options specified, 'contlistlength' used. \"jul_date\" - adds Julian date model normal distribution mean standard deviation monitored parameters. \"intercept\" - longer available. Includes intercept term state observation model. including intercept terms, occupancy detection probabilities year centred overall mean level. \"centering\" - longer available. Includes hierarchical centering model parameters. Centering change model explicitly writes way allows parameter estimates updated simultaneously. options provided vector characters, e.g. modeltype = c('indran', 'halfcauchy', 'catlistlength')","code":""},{"path":"/reference/occDetModel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Occupancy detection models — occDetModel","text":"Isaac, N.J.B., van Strien, .J., August, T.., de Zeeuw, M.P. Roy, D.B. (2014).             Statistics citizen science: extracting signals change noisy ecological data.             Methods Ecology Evolution, 5: 1052-1060. Outhwaite, C.L., Chandler, R.E., Powney, G.D., Collen, B., Gregory, R.D. & Isaac, N.J.B. (2018).             Prior specification Bayesian occupancy modelling improves analysis species occurrence data.              Ecological Indicators, 93: 333-343. Isaac, N.J.B., van Strien, .J., August, T.., de Zeeuw, M.P. Roy, D.B. (2014).             Statistics citizen science: extracting signals change noisy ecological data.             Methods Ecology Evolution, 5: 1052-1060. Outhwaite, C.L., Chandler, R.E., Powney, G.D., Collen, B., Gregory, R.D. & Isaac, N.J.B. (2018).             Prior specification Bayesian occupancy modelling improves analysis species occurrence data.              Ecological Indicators, 93: 333-343.","code":""},{"path":"/reference/occDetModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Occupancy detection models — occDetModel","text":"","code":"if (FALSE) {  # Create data set.seed(125) n <- 15000 #size of dataset nyr <- 20 # number of years in data nSamples <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"1980/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(1980+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(rDates, size = n, TRUE)  # run the model with these data for one species # using defaults results <- occDetModel(taxa = taxa,                        site = site,                        survey = survey,                        species_list = 'a',                        write_results = FALSE,                        n_iterations = 1000,                        burnin = 10,                        thinning = 2)                         # run with a different model type results <- occDetModel(taxa = taxa,                        site = site,                        survey = survey,                        species_list = 'a',                        write_results = FALSE,                        n_iterations = 1000,                        burnin = 10,                        thinning = 2,                        seed = 125,                         modeltype = c(\"indran\", \"intercept\"))                         # run with regions  # Create region definitions regions <- data.frame(site = unique(site),                       region1 = c(rep(1, 20), rep(0, 30)),                       region2 = c(rep(0, 20), rep(1, 15), rep(0, 15)),                       region3 = c(rep(0, 20), rep(0, 15), rep(1, 15)))   results <- occDetModel(taxa = taxa,                        site = site,                        survey = survey,                        species_list = 'a',                        write_results = FALSE,                        n_iterations = 1000,                        burnin = 10,                        thinning = 2,                        seed = 125,                         modeltype = c(\"indran\", \"intercept\"),                        regional_codes = regions,                        region_aggs = list(agg1 = c('region1', 'region2')))        }"},{"path":"/reference/occurrenceChange.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate percentage change between two years using Bayesian output — occurrenceChange","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"Using data returned occDetModel/occDetFunc function models  trend two years iteration models. Several options available method used calculate trend. distribution results used calculate mean estimate 95","code":""},{"path":"/reference/occurrenceChange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"","code":"occurrenceChange(   bayesOut,   firstYear = NULL,   lastYear = NULL,   change = \"growthrate\",   region = NULL )"},{"path":"/reference/occurrenceChange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"bayesOut occDet object returned occDetModel occDetFunc. firstYear numeric, first year change estimated. Defaults final year dataset lastYear numeric, last year change estimated. Defaults first year dataset change character string specifies type change calculated, default annual growth rate.  See details options. region character string specifying region name change determined regional estimates occupancy. Region names must match model output.","code":""},{"path":"/reference/occurrenceChange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"list giving mean, median, credible intervals raw data estimations. recommended use median value.","code":""},{"path":"/reference/occurrenceChange.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"change used specify change measure calculated. four options choose : difference, percentdif, growthrate lineargrowth. difference calculates simple difference first last year. percentdif calculates percentage difference first last year. growthrate calculates annual growth rate across years. lineargrowth calculates linear growth rate linear model.","code":""},{"path":"/reference/occurrenceChange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate percentage change between two years using Bayesian output — occurrenceChange","text":"","code":"if (FALSE) {  #' # Create data n <- 15000 #size of dataset nyr <- 20 # number of years in data nSamples <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"1980/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(1980+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(rDates, size = n, TRUE)  # run the model with these data for one species results <- occDetModel(taxa = taxa,                        site = site,                        survey = survey,                        species_list = c('a','m','g'),                        write_results = FALSE,                        n_iterations = 1000,                        burnin = 10,                        thinning = 2)   # estimate the change for one species        change <- occurrenceChange(firstYear = 1990,                             lastYear = 1999,                             bayesOut = results$a)    }"},{"path":"/reference/plot.occDet.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot occDet Objects — plot.occDet","title":"Plot occDet Objects — plot.occDet","text":"Plot occDet Objects","code":""},{"path":"/reference/plot.occDet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot occDet Objects — plot.occDet","text":"","code":"# S3 method for occDet plot(x, y = NULL, main = x$SPP_NAME, reg_agg = \"\", ...)"},{"path":"/reference/plot.occDet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot occDet Objects — plot.occDet","text":"x object class occDet y used main plot title, defaults species name reg_agg name region region aggregate plot. '' (default) overall occupancy estimates plotted ... Additional arguments passed ggplot","code":""},{"path":"/reference/plot_DetectionOverTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","title":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","text":"Creates plot detectability year differing list lengths occupancy model output.","code":""},{"path":"/reference/plot_DetectionOverTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","text":"","code":"plot_DetectionOverTime(model, spname = NULL, min.yr = NULL, CI = 95)"},{"path":"/reference/plot_DetectionOverTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","text":"model fitted sparta model class OccDet. spname optional name species (used plotting) min.yr Minimum year detection (e.g., 1990). CI Confidence interval","code":""},{"path":"/reference/plot_DetectionOverTime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","text":"function returns plot showing detection probability y axis year x.","code":""},{"path":"/reference/plot_DetectionOverTime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diagnostics for the detection model with respect to Length — plot_DetectionOverTime","text":"Takes object OccDet Calculates detection probability produces plot detectability time reference data type.","code":""},{"path":"/reference/plot_DetectionPhenology.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"Creates plot detectability season calculates simple statistics","code":""},{"path":"/reference/plot_DetectionPhenology.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"","code":"plot_DetectionPhenology(   model,   spname = NULL,   bins = 12,   density_function = TRUE )"},{"path":"/reference/plot_DetectionPhenology.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"model fitted sparta model class OccDet. spname optional name species (used plotting) bins number points estimate across year. Defaults 12 density_function whether model used density function fit Julian date. form implemented version 0.1.48 onwards. models ran using earlier versions package set FALSE","code":""},{"path":"/reference/plot_DetectionPhenology.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"function returns plot showing detection probability y axis Julian day x.         data within output list shows Julian day point estimated (equal number bins)         mean detection probability 95","code":""},{"path":"/reference/plot_DetectionPhenology.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"Takes object OccDet fitted jul_date option Calculates phenology detection produces plot detectability time reference data type.","code":""},{"path":"/reference/plot_DetectionPhenology.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diagnostics for the detectability with respect to Julian Date — plot_DetectionPhenology","text":"van Strien, .J., Termaat, T., Groenendijk, D., Mensing, V. & Kéry, M. (2010)             Site-occupancy models may offer new opportunities dragonfly monitoring based daily species lists.             Basic Applied Ecology, 11, 495–503.","code":""},{"path":"/reference/plot_GIS.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot GIS shape files — plot_GIS","title":"Plot GIS shape files — plot_GIS","text":"function can used plot gis data loaded shape files using readShapePoly() function contained 'maptools' R package.","code":""},{"path":"/reference/plot_GIS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot GIS shape files — plot_GIS","text":"","code":"plot_GIS(   gis_data = NULL,   main = \"\",   xlab = \"\",   ylab = \"\",   xlim = NULL,   ylim = NULL,   show.axis = TRUE,   show.grid = TRUE,   grid.div = 1,   round.grid = FALSE,   grid.col = \"grey\",   fill.col = NA,   line.col = NULL,   bg.col = \"white\",   box.col = NA,   new.window = TRUE,   no.margin = FALSE,   set.margin = TRUE,   max.dimen = 13,   cex.main = 1.2,   cex.lab = 1,   cex.axis = 0.8,   blank.plot = FALSE,   plot.shape = TRUE,   additions = FALSE,   return.dimen = TRUE )"},{"path":"/reference/plot_GIS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot GIS shape files — plot_GIS","text":"gis_data GIS object, list objects, plotted. main Text variable controlling main title placed plot - value needs text string (default == '', title blank) xlab Text variable controlling label x-axis - value needs text string (default = \"\", blank) ylab Text variable controlling label y-axis - value needs text string (default = \"\", blank) xlim Numberical variable setting lower upper limits x-axis. xlim can rounded nearest grid divison (controlled grid.div round.grid) allows specified coordinates plotted (default = NULL, fixs limits nearest grid line (see grid.divs) allows GIS shapes plotted) ylim Numberical variable setting lower upper limits y-axis. ylim can rounded nearest grid divison (controlled grid.div round.grid) allows specified coordinates plotted (default = NULL, fixs limits nearest grid line (see grid.divs) allows gis shapes plotted) show.axis Logical variable controlling whether axis plotted show.grid Logical variable determining whether overlay gridlines ontop plot grid.div Numerical variable determining interval axis ticks also gridlines. Note: show.grid = TRUE value still determines axes tick intervals (default = 1) round.grid Logical, TRUE bounding box enlarged entire grid cells shown (default = FALSE) grid.col Variable determining colour lines used overlaid grid. Value can text string named colour, numerical value, etc, see help function 'par' details (default = \"grey\"). fill.col Variable determining colour used fill landmasses plotted. Value can text string named colour, numerical value, etc, see help function 'par' details (default = NA, meaning fill) line.col Variable determining colour line used plot landmasses. Value can text string named colour, numerical value, etc, see help function 'par' details (default = NULL, results black lines) bg.col Variable determining colour background plot area. Value can text string named colour, numerical value, etc, see help function 'par' details (default = \"white\") box.col Variable determining colour border surrounding plot area (default = NA, border added plot) new.window Logical variable determining whether plot create plot new window plot within existing window/device. NOTE: new.window = TRUE window dimensions determined based upon xlim ylim order keep correct aspect ratio preserve map shape, changing new.window FALSE sizing device/window user/previous plot (default TRUE) .margin Logical variable determining whether plot include margin NOTE - main title, x-labels y-labels written margin remove margin titles/labels required (default = FALSE, plot includes margin). set.margin Logical variable. TRUE (default), margins set equal size. FALSE margins used set R environment. max.dimen Numberical variable determining maximum window dimension. Variable determines height width depend whether xlim range greater ylim range  (default = 13) cex.main Numberical variable determining relative sizing main plot title (default = 1.2) cex.lab Numberical variable determining relative sizing axis labels (default = 1) cex.axis Numberical variable determining relative sizing axis values (default = 0.8) blank.plot Logical variable determining whether function finish blank plot window created continue plotting (default =  FALSE, plotting continues) plot.shape Logical variable determining whether plot lines shape file whether setup background plot (.e grid lines, axis) outline can added later, useful outline cover plotting  symbols/colours (default = TRUE) additions Logical variable determining whether plot created scratch whether components (.e. axes, gridlines, outline) added existing plot (default = FALSE) return.dimen logical, TRUE plot dimensions returned","code":""},{"path":"/reference/plot_GIS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot GIS shape files — plot_GIS","text":"data.frame giving dimensions plot area.","code":""},{"path":"/reference/recsOverTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram of records over time — recsOverTime","title":"Histogram of records over time — recsOverTime","text":"useful function visualising data number records change time. key understanding biases may present data (Isaac et al, 2014).","code":""},{"path":"/reference/recsOverTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram of records over time — recsOverTime","text":"","code":"recsOverTime(   time_period,   Log = FALSE,   col = \"black\",   xlab = \"Year\",   ylab = ifelse(Log, \"log(Frequency)\", \"Frequency\"),   ... )"},{"path":"/reference/recsOverTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram of records over time — recsOverTime","text":"time_period numeric vector user defined time periods, date vector, long number observations. Log Logical, y-axis log scale? col Passed barplot, colour bars xlab Passed barplot, x-axis label ylab Passed barplot, y-axis label ... arguements pass barplot","code":""},{"path":"/reference/recsOverTime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram of records over time — recsOverTime","text":"plot","code":""},{"path":"/reference/recsOverTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histogram of records over time — recsOverTime","text":"","code":"if (FALSE) {  # Create data n <- 3000 #size of dataset nyr <- 10 # number of years in data nSamples <- 30 # set number of dates nSites <- 15 # set number of sites  # Create somes dates first <- as.POSIXct(strptime(\"2010/01/01\", \"%Y/%m/%d\"))  last <- as.POSIXct(strptime(paste(2010+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier time_period <- sample(rDates, size = n, TRUE)  # combine this to a dataframe (adding a final row of 'bad' data) df <- data.frame(taxa = c(taxa,'bad'),                  site = c(site,'A1'),                  time_period = c(time_period, as.POSIXct(strptime(\"1200/01/01\", \"%Y/%m/%d\"))))                   # This reveals the 'bad data'                   recsOverTime(df$time_period)  # remove and replot df <- df[format(df$time_period, '%Y') > 2000, ] recsOverTime(df$time_period)  # plot with style recsOverTime(df$time_period, col = 'blue', main = 'Records of Species A',              ylab = 'log(number of records)', Log = TRUE)   }"},{"path":"/reference/reportingRateModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Reporting Rate Models — reportingRateModel","title":"Run Reporting Rate Models — reportingRateModel","text":"Run reporting rate models assess change species occurrence time.","code":""},{"path":"/reference/reportingRateModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Reporting Rate Models — reportingRateModel","text":"","code":"reportingRateModel(   taxa,   site,   time_period,   list_length = FALSE,   site_effect = FALSE,   species_to_include = unique(taxa),   overdispersion = FALSE,   verbose = FALSE,   family = \"Binomial\",   print_progress = FALSE )"},{"path":"/reference/reportingRateModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Reporting Rate Models — reportingRateModel","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. time_period numeric vector user defined time periods, date vector, long number observations. list_length Logical, TRUE list length added models fixed effect. Note since list_length property visit model run  binomial model rather bernoulli model. site_effect Logical, TRUE site added models random effect. species_to_include character vector giving name species model. default species modelled overdispersion option allows modelling overdispersion (TRUE) models. Default FALSE. verbose option, TRUE, sets models verbose, allowing  interations model viewed. family type model use. Can \"Binomial\" \"Bernoulli\". Note list_length TRUE family defaults Bernoulli. print_progress Logical, TRUE progress printed console running models. Default TRUE","code":""},{"path":"/reference/reportingRateModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Reporting Rate Models — reportingRateModel","text":"dataframe results returned R. row gives results         single species, species name given first column, species_name.         following columns prefix (\".\") gives covariate         sufix (\".\") gives parameter covariate.  number_observations gives number visits species interest         observed. models encountered error given         column error_message. model encounter errors values         columns NA data.frame number attributes:  intercept_year - year used intercept (.e.           year whose value set 0). Setting intercept median year helps           increase model stability min_year max_year - earliest latest year           dataset (years centered intercept_year nVisits - total number visits dataset model_formula - model used, vary depending           combination arguments used","code":""},{"path":"/reference/reportingRateModel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Run Reporting Rate Models — reportingRateModel","text":"Roy, H.E., Adriaens, T., Isaac, N.J.B. et al. (2012) Invasive alien predator             causes rapid declines native European ladybirds. Diversity & Distributions,             18: 717-725. Isaac, N.J.B. et al. (2014) Extracting robust trends species' distributions              unstructured opportunistic data: comparison methods.             bioRXiv 006999, https://doi.org/10.1101/006999.","code":""},{"path":"/reference/reportingRateModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Reporting Rate Models — reportingRateModel","text":"","code":"if (FALSE) {  # Create data n <- 3000 #size of dataset nyr <- 10 # number of years in data nSamples <- 30 # set number of dates nSites <- 15 # set number of sites  # Create somes dates first <- as.POSIXct(strptime(\"2010/01/01\", \"%Y/%m/%d\"))  last <- as.POSIXct(strptime(paste(2010+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier time_period <- sample(rDates, size = n, TRUE)  # combine this to a dataframe (adding a final row of 'bad' data) df <- data.frame(taxa = c(taxa,'bad'),                  site = c(site,'A1'),                  time_period = c(time_period, as.POSIXct(strptime(\"1200/01/01\", \"%Y/%m/%d\"))))  # Run the model RR_out <- reportingRateModel(df$taxa, df$site, df$time_period, print_progress = TRUE) head(RR_out)  }"},{"path":"/reference/simOccData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate for Occupancy detection models — simOccData","title":"Simulate for Occupancy detection models — simOccData","text":"Simulates data suitable use sparta user defines parameters data generation present works just one species generates list length probabalistically","code":""},{"path":"/reference/simOccData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate for Occupancy detection models — simOccData","text":"","code":"simOccData(   nsites = 20,   nvisits = 100,   nTP = 10,   psi = 0.5,   trend = -0.01,   mu.lp = -1,   tau.lp = 10,   beta1 = 182,   beta2 = 20,   beta3 = 100,   dtype2.p = 3,   dtype3.p = 10,   JD_range = NULL )"},{"path":"/reference/simOccData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate for Occupancy detection models — simOccData","text":"nsites numeric, number sites simulated data sampled. nvisits numeric, number visits simulated data sampled. nTP numeric, number time periods simulated data sampled. psi probability site occupied time period 1. trend proportion sites change state time period. decreasing trends probability persistence one time period next 1 + trend value. Probability colonisation 0. increasing trends probability unoccupied site colonised one time period next trend value. Probability persistence 1. mu.lp mean value normal distribution year effect (alpha.p) observation model. tau.lp precision value normal distribution year effect (alpha.p) observation model. beta1 mean value normal distribution effect Julian day observation model.must valid Julian date beta2 standard deviation normal distribution effect Julian day observation model. beta3 parameter logit scale governing magnitude Julian date effect observation model. dtype2.p parameter (logit scale) list length 2-3 observation model. dtype3.p parameter (logit scale) list length 4 observation model. JD_range range Julian dates upon visits can take place. null Julian date ranges 1 365.","code":""},{"path":"/reference/simOccData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate for Occupancy detection models — simOccData","text":"list, first two elements ('spp_vis' & 'occDetData') mimic output occDetFunc. third element ('Z') presence-absence state variable fourth ('p') true probability detection.","code":""},{"path":"/reference/simOccData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate for Occupancy detection models — simOccData","text":"","code":"if (FALSE) {  # set the sparta options sparta_options <- c('ranwalk', # prior on occupancy is set by last year's posterior                    'jul_date', # use the Julian date as a covariate on the detection probability                    'catlistlength', # categorises the visits into three sets of 'qualities'                    'halfcauchy') # prior on the precisions  # simulate some data mydata <- simOccData(nvisit=200, nsite=10, nTP=5, psi=0.5, beta1=182, beta2=20, beta3=100) with(mydata, plot(occDetdata$Jul_date, p))  # run the occupancy model model out <- occDetFunc('mysp', mydata$occDetdata, mydata$spp_vis, n_iter = 1e4,                   modeltype = sparta_options, return_data=TRUE)  out$BUGSoutput plot_DetectionPhenology(out)  qplot(data=melt(out$BUGSoutput$sims.array), geom='line',      x=Var1, col=factor(Var2), y=value) +  facet_wrap(~Var3, ncol=4, scales='free')  }"},{"path":"/reference/siteSelection.html","id":null,"dir":"Reference","previous_headings":"","what":"Site selection method — siteSelection","title":"Site selection method — siteSelection","text":"function uses method outlined Roy et al (2012) Isaac et al (2014) selecting well-sampled sites dataset using list length number years selection criteria.","code":""},{"path":"/reference/siteSelection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Site selection method — siteSelection","text":"","code":"siteSelection(taxa, site, time_period, minL, minTP, LFirst = TRUE)"},{"path":"/reference/siteSelection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Site selection method — siteSelection","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. time_period numeric vector user defined time periods, date vector, long number observations. minL numeric, minimum number taxa recorded site given time period  (list-length) visit considered well sampled. minTP numeric, minimum number time periods, time_period date minimum number years, site must sampled considered well sampled. LFirst Logical, TRUE data first filtered list-length time periods, else time period list-length","code":""},{"path":"/reference/siteSelection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Site selection method — siteSelection","text":"data.frame data forefills selection criteria","code":""},{"path":"/reference/siteSelection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Site selection method — siteSelection","text":"needed","code":""},{"path":"/reference/siteSelection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Site selection method — siteSelection","text":"","code":"# Create data n <- 150 #size of dataset nyr <- 8 # number of years in data nSamples <- 20 # set number of dates  # Create somes dates first <- as.POSIXct(strptime(\"2003/01/01\", \"%Y/%m/%d\"))  last <- as.POSIXct(strptime(paste(2003+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(c('one', 'two', 'three'), size = n, TRUE)  # the date of visit is selected at random from those created earlier time_period <- sample(rDates, size = n, TRUE)  # combine this to a dataframe df <- data.frame(taxa, site, time_period) head(df) #>   taxa  site         time_period #> 1    r   one 2007-01-22 20:18:55 #> 2    e   two 2008-05-07 19:30:53 #> 3    w three 2006-03-25 19:46:36 #> 4    k   one 2004-09-30 01:53:14 #> 5    a   two 2006-03-25 19:46:36 #> 6    d   two 2008-05-07 19:30:53  # Use the site selection function on this simulated data dfSEL  <- siteSelection(df$taxa, df$site, df$time_period, minL = 4, minTP = 3) #> Warning: 10 out of 150 observations will be removed as duplicates"},{"path":"/reference/siteSelectionMinL.html","id":null,"dir":"Reference","previous_headings":"","what":"List-length site selection — siteSelectionMinL","title":"List-length site selection — siteSelectionMinL","text":"function uses part method outlined Roy et al (2012) Isaac et al (2014) selecting well-sampled sites dataset using list length . siteSelection wrapper function performs complete site selection process outlined papers.","code":""},{"path":"/reference/siteSelectionMinL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List-length site selection — siteSelectionMinL","text":"","code":"siteSelectionMinL(taxa, site, time_period, minL)"},{"path":"/reference/siteSelectionMinL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List-length site selection — siteSelectionMinL","text":"taxa character vector taxon names site character vector site names time_period Anumeric vector user defined time periods, date vector minL numeric, minimum number taxa recorded site given time period  (list-length) visit considered well sampled.","code":""},{"path":"/reference/siteSelectionMinL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List-length site selection — siteSelectionMinL","text":"data.frame data forefills selection criteria. data two attributes: visits gives total number visits dataset (unique combinations site time_period), success gives number visits satify selection criteria","code":""},{"path":"/reference/siteSelectionMinL.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"List-length site selection — siteSelectionMinL","text":"needed","code":""},{"path":"/reference/siteSelectionMinTP.html","id":null,"dir":"Reference","previous_headings":"","what":"Minimum time-period site selection — siteSelectionMinTP","title":"Minimum time-period site selection — siteSelectionMinTP","text":"function uses part method outlined Roy et al (2012) Isaac et al (2014) selecting well-sampled sites dataset using number time periods . siteSelection wrapper function performs complete site selection process outlined papers.","code":""},{"path":"/reference/siteSelectionMinTP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Minimum time-period site selection — siteSelectionMinTP","text":"","code":"siteSelectionMinTP(taxa, site, time_period, minTP)"},{"path":"/reference/siteSelectionMinTP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Minimum time-period site selection — siteSelectionMinTP","text":"taxa character vector taxon names site character vector site names time_period numeric vector user defined time periods, date vector minTP numeric, minimum number time periods, time_period date minimum number years, site must sampled considered well sampled.","code":""},{"path":"/reference/siteSelectionMinTP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Minimum time-period site selection — siteSelectionMinTP","text":"data.frame data forefills selection criteria. data two attributes: sites gives total number sites dataset, sucess gives number sites satify selection criteria","code":""},{"path":"/reference/siteSelectionMinTP.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Minimum time-period site selection — siteSelectionMinTP","text":"needed","code":""},{"path":"/reference/sparta.html","id":null,"dir":"Reference","previous_headings":"","what":"sparta Trend Analysis for Unstructured Data — sparta","title":"sparta Trend Analysis for Unstructured Data — sparta","text":"Sparta package includes methods used analyse trends unstructured occurrence datasets. Methods included package include Frescalo, Telfer's change index, Reporting rate models Bayesian Occupancy models. methods reviewed  Issac et al (2014), available http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12254/abstract","code":""},{"path":[]},{"path":"/reference/sparta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"sparta Trend Analysis for Unstructured Data — sparta","text":"Maintainer: Dylan Carbone dylcar@ceh.ac.uk (ORCID) Authors: Nick Isaac (ORCID) Tom August tomaug@ceh.ac.uk (ORCID) Colin Harrower (ORCID) Jack Hatfield (ORCID) Mark Hill (ORCID) Francesca Mancini (ORCID) Charlie Outhwaite (ORCID) Gary Powney (ORCID)","code":""},{"path":"/reference/telfer.html","id":null,"dir":"Reference","previous_headings":"","what":"Telfer's change index — telfer","title":"Telfer's change index — telfer","text":"Telfers change index designed assess relative change range size species  two time periods (Telfer et al 2002). function can take multiple time periods complete pairwise comparisons.","code":""},{"path":"/reference/telfer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Telfer's change index — telfer","text":"","code":"telfer(   taxa,   site,   time_period,   minSite = 5,   useIterations = TRUE,   iterations = 10 )"},{"path":"/reference/telfer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Telfer's change index — telfer","text":"taxa character vector taxon names site character vector site names time_period numeric vector user defined time periods, date vector minSite minimum number sites occupied first time period order trend calculated taxon. useIterations logical variable indicating whether iterations used. Iterations used account increased variation logit proportions close zero one (see Telfer et al 2002). Default TRUE iterations useIterations TRUE, parameter indicates number iterations used. Telfer et al 2002 number iterations used 7 8 two datasets applied. defualt 10.","code":""},{"path":"/reference/telfer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Telfer's change index — telfer","text":"Telfer, M.G., Preston, C.D., & Rothery, P. (2002) general method             measuring relative change range size biological atlas data.             Biological Conservation, 107, 99-109.","code":""},{"path":"/reference/telfer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Telfer's change index — telfer","text":"","code":"# Create fake data SS <- 5000 # number of observations taxa <- sample(letters, SS, replace = TRUE) site <- sample(paste('A', 1:20, sep = ''), SS, replace = TRUE) time_period <- sample(1:3, SS, replace = TRUE)  TelferResult <- telfer(taxa, site, time_period) #> Warning: 3500 out of 5000 observations will be removed as duplicates head(TelferResult) #>   taxa Nsite_1.x Nsite_2.x Telfer_1_2 Nsite_1.y Nsite_3.x Telfer_1_3 Nsite_2.y #> 1    a        19        19 -0.3496937        19        20  1.1349254        19 #> 2    b        19        20  1.0791037        19        18 -1.0236982        20 #> 3    c        19        19 -0.3496937        19        20  1.1349254        19 #> 4    d        18        17 -1.3360467        18        20  1.3049751        17 #> 5    e        20        20  0.6735143        20        18 -1.5819806        20 #> 6    f        19        20  1.0791037        19        19 -0.3132701        20 #>   Nsite_3.y Telfer_2_3 #> 1        20  1.0550502 #> 2        18 -1.4056967 #> 3        20  1.0550502 #> 4        20  1.1993588 #> 5        18 -1.4056967 #> 6        19 -0.6252982"},{"path":"/reference/unicorns.html","id":null,"dir":"Reference","previous_headings":"","what":"A fictional dataset of unicorn sightings — unicorns","title":"A fictional dataset of unicorn sightings — unicorns","text":"fictional occurrence dataset 20 species unicorn UK. dataset column names, start_date, end_date, site species respectively, corresponding start datetime occurence, end datetime occurence, site ID, species ID.","code":""},{"path":"/reference/unicorns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A fictional dataset of unicorn sightings — unicorns","text":"","code":"unicorns"},{"path":"/reference/unicorns.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A fictional dataset of unicorn sightings — unicorns","text":"Tom August, 2015-07-01","code":""},{"path":"/reference/visitsSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarises visits — visitsSummary","title":"Summarises visits — visitsSummary","text":"function takes formatOccData object returns dataframe summarising percentage total sites visited twice (.e. revisited) within closure period, well mean number visits sites visited two times closure period.","code":""},{"path":"/reference/visitsSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarises visits — visitsSummary","text":"","code":"visitsSummary(x)"},{"path":"/reference/visitsSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarises visits — visitsSummary","text":"x formatOccData object (object class List, 2 dataframe components (spp_vis occDetdata).","code":""},{"path":"/reference/visitsSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarises visits — visitsSummary","text":"dataframe forefills selection criteria.","code":""},{"path":"/reference/visitsSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarises visits — visitsSummary","text":"","code":"if (FALSE) {  set.seed(123)  # Create data n <- 15000 #size of dataset nyr <- 20 # number of years in data nSamples <- 100 # set number of dates nSites <- 50 # set number of sites  # Create somes dates first <- as.Date(strptime(\"2010/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(2010+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # sites are visited randomly site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE)  # the date of visit is selected at random from those created earlier survey <- sample(rDates, size = n, TRUE)  # Format the data visitData <- formatOccData(taxa = taxa, site = site, survey = survey)  # Summarise visits visitsSummary(visitData)  }"},{"path":"/reference/WSS.html","id":null,"dir":"Reference","previous_headings":"","what":"Well sampled sites model — WSS","title":"Well sampled sites model — WSS","text":"function wrapper siteSelection reportingRateModel allows users run well sampled sites analysis Roy et al (2012).","code":""},{"path":"/reference/WSS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Well sampled sites model — WSS","text":"","code":"WSS(   taxa,   site,   time_period,   minL = 2,   minTP = 3,   species_to_include = unique(taxa),   overdispersion = FALSE,   family = \"Binomial\",   verbose = FALSE,   print_progress = FALSE )"},{"path":"/reference/WSS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Well sampled sites model — WSS","text":"taxa character vector taxon names, long number observations. site character vector site names, long number observations. time_period numeric vector user defined time periods, date vector, long number observations. minL numeric, minimum number taxa recorded site given time period  (list-length) visit considered well sampled. minTP numeric, minimum number time periods, time_period date minimum number years, site must sampled considered well sampled. species_to_include character vector giving name species model. default species modelled overdispersion option allows modelling overdispersion (TRUE) models. Default FALSE. family type model use. Can \"Binomial\" \"Bernoulli\". verbose option, TRUE, sets models verbose, allowing  interations model viewed. print_progress Logical, TRUE progress printed console running models. Default TRUE","code":""},{"path":"/reference/WSS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Well sampled sites model — WSS","text":"dataframe results returned R. row gives results         single species, species name given first column, species_name.         following columns prefix (\".\") gives covariate         sufix (\".\") gives parameter covariate.  number_observations gives number visits species interest         observed. models encountered error given         column error_message. data.frame number attributes:  intercept_year - year used intercept (.e.           year whose value set 0). Setting intercept median year helps           increase model stability min_year max_year - earliest latest year           dataset (years centered intercept_year nVisits - total number visits dataset model_formula - model used, vary depending           combination arguements used minL - setting minL used site selection minTP - setting minTP used site selection","code":""},{"path":"/reference/WSS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Well sampled sites model — WSS","text":"Roy, H.E., Adriaens, T., Isaac, N.J.B. et al. (2012) Invasive alien predator             causes rapid declines native European ladybirds. Diversity & Distributions,             18, 717-725.","code":""},{"path":"/reference/WSS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Well sampled sites model — WSS","text":"","code":"# Create data n <- 1500 #size of dataset nyr <- 8 # number of years in data nSamples <- 20 # set number of dates  # Create somes dates first <- as.POSIXct(strptime(\"2003/01/01\", \"%Y/%m/%d\")) last <- as.POSIXct(strptime(paste(2003+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\")) dt <- last-first rDates <- first + (runif(nSamples)*dt)  # taxa are set as random letters taxa <- sample(letters, size = n, TRUE)  # three sites are visited randomly site <- sample(c('one', 'two', 'three'), size = n, TRUE)  # the date of visit is selected at random from those created earlier time_period <- sample(rDates, size = n, TRUE)  # combine this to a dataframe df <- data.frame(taxa, site, time_period)  results <- WSS(df$taxa,                 df$site,                 df$time_period,                 minL = 4,                 minTP = 3,                 species_to_include = c('a', 'b', 'c')) #> Warning: 537 out of 1500 observations will be removed as duplicates #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular')  # Look at the results for the first few species head(results) #>   species_name intercept.estimate year.estimate intercept.stderror #> 1            a          0.3943994   -0.02898427          0.2664725 #> 2            b          0.2753493    0.01740075          0.2641437 #> 3            c          0.7243898    0.23104897          0.4574995 #>   year.stderror intercept.zvalue year.zvalue intercept.pvalue year.pvalue #> 1     0.1057096         1.480075  -0.2741876        0.1388532  0.78394046 #> 2     0.1042904         1.042422   0.1668491        0.2972159  0.86748882 #> 3     0.1175658         1.583367   1.9652737        0.1133378  0.04938256 #>   observations #> 1           36 #> 2           34 #> 3           38 # Look at the attributes of the object returned attributes(results) #> $names #>  [1] \"species_name\"       \"intercept.estimate\" \"year.estimate\"      #>  [4] \"intercept.stderror\" \"year.stderror\"      \"intercept.zvalue\"   #>  [7] \"year.zvalue\"        \"intercept.pvalue\"   \"year.pvalue\"        #> [10] \"observations\"       #>  #> $class #> [1] \"data.frame\" #>  #> $row.names #> [1] 1 2 3 #>  #> $intercept_year #> [1] 2007 #>  #> $min_year #> [1] -4 #>  #> $max_year #> [1] 3 #>  #> $nVisits #> [1] 60 #>  #> $model_formula #> [1] \"cbind(successes, failures) ~ year + (1|site)\" #>  #> $minL #> [1] 4 #>  #> $minTP #> [1] 3 #>"}]
